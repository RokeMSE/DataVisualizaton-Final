# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import re
from collections import Counter
import csv
from io import BytesIO, StringIO
import statsmodels.api as sm
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import os
from dotenv import load_dotenv
import google.generativeai as genai

# --- AI Config ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
AI_MODEL_NAME = "gemini-2.0-flash"

genai_model = None
ai_configured_successfully = False

if not GEMINI_API_KEY:
    st.error("üö® Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY. Vui l√≤ng thi·∫øt l·∫≠p trong file .env.")
else:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        genai_model = genai.GenerativeModel(AI_MODEL_NAME)
        ai_configured_successfully = True
    except Exception as e:
        ai_configured_successfully = False

# --- Page Config ---
st.set_page_config(
    page_title="Dashboard Ph√¢n T√≠ch Tuy·ªÉn D·ª•ng VN",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

sns.set_palette("colorblind")
PALETTE = ["#88CCEE", "#44AA99", "#117733", "#999933", "#DDCC77", "#CC6677", "#882255", "#AA4499"]

def save_fig_to_pdf(fig):
    buffer = BytesIO()
    fig.savefig(buffer, format='pdf', bbox_inches='tight')
    buffer.seek(0)
    return buffer

# --- Helper Functions ---
@st.cache_data(show_spinner="ƒêang t·∫£i d·ªØ li·ªáu...")
def load_data(uploaded_file):
    """T·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file CSV ƒë∆∞·ª£c t·∫£i l√™n."""
    try:
        df = pd.read_csv(
            uploaded_file,
            encoding='utf-8',
            na_values=["None", " ", "UNKNOWN", -1, 999, "NA", "N/A", "NULL", ""],
        )
        st.session_state.original_filename = uploaded_file.name

        # X·ª≠ l√Ω job_title
        if 'job_title' in df.columns:
            unique_types = df['job_title'].apply(type).unique()
            if len(unique_types) > 1:
                st.warning(f"C·ªôt job_title ch·ª©a nhi·ªÅu ki·ªÉu d·ªØ li·ªáu: {unique_types}. ƒêang chu·∫©n h√≥a th√†nh chu·ªói.")
            df['job_title'] = df['job_title'].astype(str).replace('nan', 'Kh√¥ng x√°c ƒë·ªãnh').str.strip()
        else:
            df['job_title'] = 'Kh√¥ng x√°c ƒë·ªãnh'

        # X·ª≠ l√Ω c√°c c·ªôt s·ªë
        salary_cols = ['min_salary_mil_vnd', 'max_salary_mil_vnd']
        for col in salary_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            else:
                df[col] = np.nan

        exp_cols = ['min_experience_years', 'max_experience_years']
        for col in exp_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').clip(0, 50)
            else:
                df[col] = np.nan

        # X·ª≠ l√Ω c√°c c·ªôt ph√¢n lo·∫°i
        categorical_cols = ['primary_location', 'primary_category', 'position', 'order']
        for col in categorical_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).fillna('Kh√¥ng x√°c ƒë·ªãnh').str.strip()
                df[col] = df[col].astype('category')
            else:
                df[col] = pd.Categorical(['Kh√¥ng x√°c ƒë·ªãnh'] * len(df))

        if 'job_requirements' in df.columns:
            df['job_requirements'] = df['job_requirements'].astype(str).fillna('')
        else:
            df['job_requirements'] = ''

        if 'company_title' not in df.columns:
            df['company_title'] = 'Kh√¥ng x√°c ƒë·ªãnh'
        else:
            df['company_title'] = df['company_title'].astype(str).str.strip()

        # Chuy·ªÉn c√°c c·ªôt StringDtype th√†nh object
        for col in df.columns:
            if df[col].dtype == 'string':
                df[col] = df[col].astype('object')

        # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu t·ªëi ∆∞u
        df = df.convert_dtypes()

        # Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu
        # st.write("Ki·ªÉu d·ªØ li·ªáu c·ªßa c√°c c·ªôt sau khi x·ª≠ l√Ω:")
        # st.write(df.dtypes)

        if df.empty:
            st.error("D·ªØ li·ªáu r·ªóng sau khi ƒë·ªçc file.")
            return None

        return df

    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file CSV: {e}")
        st.exception(e)
        return None

@st.cache_data
def extract_skills_from_requirements(text_series, num_skills=30):
    """Tr√≠ch xu·∫•t v√† ƒë·∫øm t·∫ßn su·∫•t c√°c k·ªπ nƒÉng t·ª´ c·ªôt job_requirements."""
    skills_keywords = [
        'python', 'java', 'sql', 'javascript', 'react', 'angular', 'vue', 'node.js', 'nodejs',
        'c#', '.net', 'php', 'ruby', 'swift', 'kotlin', 'android', 'ios', 'flutter', 'html', 'css',
        'typescript', 'go', 'rust', 'scala', 'perl', 'c++', ' c ',
        'mysql', 'postgresql', 'sql server', 'mongodb', 'oracle', 'redis', 'cassandra', 'nosql',
        'aws', 'azure', 'gcp', 'google cloud', 'docker', 'kubernetes', 'k8s', 'terraform', 'linux', 'jenkins', 'git', 'ci/cd', 'devops', 'ansible',
        'excel', 'power bi', 'tableau', 'qlik', 'data analysis', 'ph√¢n t√≠ch d·ªØ li·ªáu', 'machine learning', 'h·ªçc m√°y', 'ai', 'tr√≠ tu·ªá nh√¢n t·∫°o', 'deep learning', 'h·ªçc s√¢u',
        'pandas', 'numpy', 'scikit-learn', 'sklearn', 'tensorflow', 'pytorch', 'keras', 'hadoop', 'spark', 'big data', 'd·ªØ li·ªáu l·ªõn', 'data warehouse', 'data mining',
        'project management', 'qu·∫£n l√Ω d·ª± √°n', 'agile', 'scrum', 'communication', 'giao ti·∫øp', 'leadership', 'l√£nh ƒë·∫°o', 'teamwork', 'l√†m vi·ªác nh√≥m',
        'problem solving', 'gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ', 'critical thinking', 't∆∞ duy ph·∫£n bi·ªán', 'english', 'ti·∫øng anh', 'japanese', 'ti·∫øng nh·∫≠t', 'korean', 'ti·∫øng h√†n', 'chinese', 'ti·∫øng trung',
        'marketing', 'digital marketing', 'sales', 'b√°n h√†ng', 'seo', 'sem', 'content', 'social media',
        'finance', 't√†i ch√≠nh', 'accounting', 'k·∫ø to√°n', 'auditing', 'ki·ªÉm to√°n', 'banking', 'ng√¢n h√†ng',
        'hr', 'nh√¢n s·ª±', 'recruitment', 'tuy·ªÉn d·ª•ng', 'talent acquisition', 'c&b', 'payroll',
        'customer service', 'chƒÉm s√≥c kh√°ch h√†ng', 'support', 'h·ªó tr·ª£',
        'design', 'ui', 'ux', 'photoshop', 'illustrator', 'figma', 'sketch', 'graphic design',
        'autocad', 'revit', 'sap', 'erp', 'logistics', 'supply chain', 'chu·ªói cung ·ª©ng', 'teaching', 'gi·∫£ng d·∫°y', 'research', 'nghi√™n c·ª©u', 'writing', 'vi·∫øt l√°ch'
    ]
    text = ' '.join(text_series.astype(str).str.lower())
    skill_counts = Counter()
    for skill in skills_keywords:
        pattern = r'(?:^|\s|[.,;!?():\'"])' + re.escape(skill).replace(r'\.', r'[\.\s-]?').replace(r'\-', r'[\s-]?') + r'(?:$|\s|[.,;!?():\'"])'
        try:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            count = sum(1 for _ in matches)
            if count > 0:
                normalized_skill = skill.replace('\\', '').replace('.', '').replace('-', '').replace(' ', '')
                existing_keys = [k for k in skill_counts if k.replace('.', '').replace('-', '').replace(' ', '') == normalized_skill]
                if existing_keys:
                    chosen_key = min(existing_keys + [skill.replace('\\', '')], key=len)
                    skill_counts[chosen_key] += count
                    for other_key in existing_keys:
                        if other_key != chosen_key and other_key in skill_counts:
                            skill_counts[chosen_key] += skill_counts.pop(other_key)
                else:
                    skill_counts[skill.replace('\\', '')] += count
        except re.error:
            pass
    top_skills = skill_counts.most_common(num_skills)
    return pd.DataFrame(top_skills, columns=['K·ªπ nƒÉng', 'S·ªë l·∫ßn xu·∫•t hi·ªán']), text

@st.cache_resource
def train_salary_model(df_train):
    """Hu·∫•n luy·ªán m√¥ h√¨nh d·ª± ƒëo√°n l∆∞∆°ng (min_salary_mil_vnd)."""
    model_features = ['min_experience_years', 'primary_category', 'primary_location']
    target = 'min_salary_mil_vnd'
    X = df_train[model_features]
    y = df_train[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    categorical_features = ['primary_category', 'primary_location']
    numeric_features = ['min_experience_years']
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numeric_features)
        ],
        remainder='drop'
    )
    model_choice = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10, min_samples_leaf=5, oob_score=True)
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', model_choice)
    ])
    try:
        pipeline.fit(X_train, y_train)
        oob_score = pipeline.named_steps['regressor'].oob_score_ if hasattr(pipeline.named_steps['regressor'], 'oob_score_') else None
    except Exception as e:
        st.error(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {e}")
        return None, None, None, None, None
    y_pred = pipeline.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    results_df = pd.DataFrame({'Th·ª±c t·∫ø': y_test, 'D·ª± ƒëo√°n': y_pred})
    st.session_state.model_pipeline = pipeline
    return results_df, rmse, mae, r2, oob_score

def get_dataset_info(df):
    if df is None:
        return "Kh√¥ng c√≥ d·ªØ li·ªáu DataFrame ƒë·ªÉ hi·ªÉn th·ªã th√¥ng tin."
    buffer = StringIO()
    df.info(buf=buffer)
    info_str = buffer.getvalue()
    info_summary = (
        f"T·ªïng quan Dataset:\n"
        f"--------------------\n"
        f"S·ªë d√≤ng: {df.shape[0]}\n"
        f"S·ªë c·ªôt: {df.shape[1]}\n\n"
        f"Th√¥ng tin chi ti·∫øt c√°c c·ªôt (dtypes, non-null counts):\n"
        f"{info_str}\n"
        f"M·ªôt v√†i th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n cho c√°c c·ªôt s·ªë:\n"
        f"{df.describe(include=np.number).to_string()}\n\n"
        f"M·ªôt v√†i th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n cho c√°c c·ªôt object/category:\n"
        f"{df.describe(include=['object', 'category']).to_string()}"
    )
    return info_summary

def generate_feedback(data_context, query):
    global genai_model
    if not genai_model:
        return "AI model ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ho·∫∑c kh·ªüi t·∫°o th√†nh c√¥ng."
    try:
        prompt = f"""
        D·ª±a tr√™n d·ªØ li·ªáu tuy·ªÉn d·ª•ng ƒë∆∞·ª£c cung c·∫•p sau ƒë√¢y:
        <data_context>
        {data_context}
        </data_context>

        H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau m·ªôt c√°ch chi ti·∫øt v√† h·ªØu √≠ch (b·∫±ng ng√¥n ng·ªØ c·ªßa user' input): "{query}"
        """
        response = genai_model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói khi giao ti·∫øp v·ªõi AI: {str(e)}"

@st.cache_data
def convert_df_to_csv(df):
    """Chuy·ªÉn ƒë·ªïi DataFrame th√†nh bytes CSV UTF-8."""
    return df.to_csv(index=False).encode('utf-8')

# --- Session State ---
if 'df_jobs' not in st.session_state:
    st.session_state.df_jobs = None
    st.session_state.df_filtered = None
    st.session_state.original_filename = ""
    st.session_state.filters = {}
    st.session_state.model_results = None
    st.session_state.model_metrics = {}
    st.session_state.model_pipeline = None

# --- Sidebar ---
st.sidebar.title("B·∫£ng ƒëi·ªÅu khi·ªÉn")
uploaded_file = st.sidebar.file_uploader(
    "üìÅ T·∫£i l√™n t·ªáp CSV",
    type=["csv"],
    help="T·∫£i l√™n file CSV ch·ª©a d·ªØ li·ªáu tuy·ªÉn d·ª•ng ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch (UTF-8)."
)

if uploaded_file is not None:
    if st.session_state.df_jobs is None or st.session_state.original_filename != uploaded_file.name:
        with st.spinner("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu..."):
            st.session_state.df_jobs = load_data(uploaded_file)
            st.session_state.filters = {}
            st.session_state.model_results = None
            st.session_state.model_metrics = {}
            st.session_state.model_pipeline = None

if st.session_state.df_jobs is not None:
    df_jobs = st.session_state.df_jobs
    
    st.sidebar.header("ƒêi·ªÅu H∆∞·ªõng")
    page_options = [
        "üè† Trang Ch·ªß & T·ªïng Quan",
        "üìä Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng",
        "üí∞ Ph√¢n T√≠ch L∆∞∆°ng & Kinh Nghi·ªám",
        "üõ†Ô∏è Ph√¢n T√≠ch K·ªπ NƒÉng",
        "ü§ñ D·ª± ƒêo√°n L∆∞∆°ng (ML)",
        "üìà Th·ªëng K√™ M√¥ T·∫£",
        "üí° C·ªë v·∫•n AI (Gemini)"
    ]
    selected_page = st.sidebar.radio(
        "Ch·ªçn trang:",
        page_options,
        key='page_navigation'
    )
    
    st.sidebar.header("B·ªô l·ªçc d·ªØ li·ªáu")
    locations = sorted(df_jobs['primary_location'].astype(str).unique())
    categories = sorted(df_jobs['primary_category'].astype(str).unique())
    selected_location = st.sidebar.multiselect(
        'üìç Ch·ªçn ƒê·ªãa ƒëi·ªÉm:', options=locations,
        default=locations,
        key='filter_location'
    )
    selected_category = st.sidebar.multiselect(
        'üìÇ Ch·ªçn Ng√†nh ngh·ªÅ:', options=categories,
        default=categories,
        key='filter_category'
    )
    exp_col = 'min_experience_years'
    if exp_col in df_jobs.columns and df_jobs[exp_col].notna().any():
        min_exp_val = int(df_jobs[exp_col].min(skipna=True))
        max_exp_val = int(df_jobs[exp_col].max(skipna=True))
        exp_default = (min_exp_val, max_exp_val)
        selected_exp_range = st.sidebar.slider(
            '‚è≥ Kinh nghi·ªám t·ªëi thi·ªÉu (nƒÉm):', min_value=min_exp_val, max_value=max_exp_val,
            value=exp_default, key='filter_experience'
        )
    else:
        selected_exp_range = None
    salary_col = 'min_salary_mil_vnd'
    if salary_col in df_jobs.columns and df_jobs[salary_col].notna().any():
        min_sal_val = float(df_jobs[salary_col].min(skipna=True))
        max_sal_val = float(df_jobs[salary_col].quantile(0.99, interpolation='nearest'))
        if min_sal_val >= max_sal_val:
            max_sal_val = float(df_jobs[salary_col].max(skipna=True))
            if min_sal_val > max_sal_val:
                min_sal_val = max_sal_val
        sal_default = (min_sal_val, max_sal_val)
        salary_median = df_jobs[salary_col].median()
        median_text = f" ({salary_median:.0f} Tr Median)" if pd.notna(salary_median) else ""
        selected_salary_range = st.sidebar.slider(
            f'üí∞ L∆∞∆°ng t·ªëi thi·ªÉu{median_text}:',
            min_value=min_sal_val, max_value=max_sal_val,
            value=sal_default, step=0.5, key='filter_salary',
            format="%.1f Tri·ªáu VND"
        )
    else:
        selected_salary_range = None
    st.session_state.filters = {
        'location': selected_location,
        'category': selected_category,
        'experience': selected_exp_range,
        'salary': selected_salary_range
    }
    df_filtered = df_jobs.copy()
    current_filters = st.session_state.filters
    if current_filters.get('location'):
        df_filtered = df_filtered[df_filtered['primary_location'].isin(current_filters['location'])]
    if current_filters.get('category'):
        df_filtered = df_filtered[df_filtered['primary_category'].isin(current_filters['category'])]
    if current_filters.get('experience') and exp_col in df_filtered.columns:
        df_filtered = df_filtered[
            df_filtered[exp_col].between(current_filters['experience'][0], current_filters['experience'][1], inclusive='both')
        ]
    if current_filters.get('salary') and salary_col in df_filtered.columns:
        df_filtered = df_filtered[
            df_filtered[salary_col].between(current_filters['salary'][0], current_filters['salary'][1], inclusive='both')
        ]
    st.session_state.df_filtered = df_filtered

    # --- Main Content ---
    if selected_page == page_options[0]:
        st.title("üè† Trang Ch·ªß & T·ªïng Quan")
        st.markdown("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi dashboard ph√¢n t√≠ch th·ªã tr∆∞·ªùng tuy·ªÉn d·ª•ng Vi·ªát Nam.")
        if st.session_state.original_filename:
            st.markdown(f"D·ªØ li·ªáu ƒëang ph√¢n t√≠ch t·ª´ file: `{st.session_state.original_filename}`")
        st.subheader("Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu (T·ªïng th·ªÉ)")
        with st.expander("Xem chi ti·∫øt t·ª∑ l·ªá thi·∫øu c·ªßa c√°c c·ªôt"):
            if 'df_jobs' in st.session_state and st.session_state.df_jobs is not None:
                missing_data = st.session_state.df_jobs.isnull().sum()
                if missing_data.sum() == 0:
                    st.info("Ch√∫c m·ª´ng! D·ªØ li·ªáu g·ªëc kh√¥ng c√≥ gi√° tr·ªã thi·∫øu.")
                else:
                    missing_percent = (missing_data / len(st.session_state.df_jobs)) * 100
                    missing_df = pd.DataFrame({
                        'C·ªôt': missing_data.index,
                        'S·ªë l∆∞·ª£ng thi·∫øu': missing_data.values,
                        'T·ª∑ l·ªá thi·∫øu (%)': missing_percent.values
                    })
                    missing_df = missing_df.astype({'C·ªôt': 'object'})  # Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu
                    st.dataframe(missing_df[missing_df['S·ªë l∆∞·ª£ng thi·∫øu'] > 0].sort_values('T·ª∑ l·ªá thi·∫øu (%)', ascending=False))
                    st.caption("T·ª∑ l·ªá thi·∫øu cao ·ªü c√°c c·ªôt quan tr·ªçng (l∆∞∆°ng, kinh nghi·ªám, ƒë·ªãa ƒëi·ªÉm, ng√†nh) s·∫Ω ·∫£nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng ph√¢n t√≠ch v√† kh·∫£ nƒÉng hu·∫•n luy·ªán m√¥ h√¨nh AI.")
            else:
                st.info("Ch∆∞a c√≥ d·ªØ li·ªáu g·ªëc ƒë·ªÉ ki·ªÉm tra (Vui l√≤ng t·∫£i file l√™n).")
        st.markdown("---")
        df_display = st.session_state.df_filtered
        if df_display is not None and not df_display.empty:
            st.header("üìå T·ªïng Quan (Theo b·ªô l·ªçc)")
            total_jobs_filtered = df_display.shape[0]
            unique_companies_filtered = df_display['company_title'].nunique()
            avg_min_salary_filtered = df_display['min_salary_mil_vnd'].mean()
            avg_min_exp_filtered = df_display['min_experience_years'].mean()
            kpi_cols = st.columns(4)
            kpi_cols[0].metric(label="S·ªë Tin Tuy·ªÉn D·ª•ng", value=f"{total_jobs_filtered:,}")
            kpi_cols[1].metric(label="S·ªë C√¥ng Ty Tuy·ªÉn", value=f"{unique_companies_filtered:,}")
            kpi_cols[2].metric(label="L∆∞∆°ng T·ªëi Thi·ªÉu TB", value=f"{avg_min_salary_filtered:.1f} Tr" if pd.notna(avg_min_salary_filtered) else "N/A")
            kpi_cols[3].metric(label="Kinh Nghi·ªám T·ªëi Thi·ªÉu TB", value=f"{avg_min_exp_filtered:.1f} NƒÉm" if pd.notna(avg_min_exp_filtered) else "N/A")
            st.markdown("---")
            st.subheader("Xem tr∆∞·ªõc d·ªØ li·ªáu (ƒë√£ l·ªçc)")
            if 'job_title' in df_display.columns:
                df_display['job_title'] = df_display['job_title'].astype(str).replace('nan', 'Kh√¥ng x√°c ƒë·ªãnh')
            df_display = df_display.astype({col: 'object' for col in df_display.columns if df_display[col].dtype == 'string'})
            st.dataframe(df_display.head(10), use_container_width=True, height=300)
            csv_download = convert_df_to_csv(df_display)
            st.download_button(
                label="üì• T·∫£i xu·ªëng d·ªØ li·ªáu ƒë√£ l·ªçc (CSV)",
                data=csv_download,
                file_name='filtered_job_data.csv',
                mime='text/csv',
                key='download_filtered_home_v2'
            )
        elif uploaded_file is not None:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc hi·ªán t·∫°i. Vui l√≤ng th·ª≠ ƒëi·ªÅu ch·ªânh b·ªô l·ªçc.")
        st.markdown("---")
        with st.expander("‚ÑπÔ∏è Th√¥ng tin v·ªÅ d·ªØ li·ªáu v√† d·ª± √°n", expanded=False):
            st.markdown(f"""
            * **Ngu·ªìn d·ªØ li·ªáu:** D·ªØ li·ªáu tham kh·∫£o ƒë∆∞·ª£c thu th·∫≠p t·ª´ CareerBuilder.vn (02-03/2023) - File: `{st.session_state.get("original_filename", "N/A")}`.
            * **X·ª≠ l√Ω:** D·ªØ li·ªáu ƒë√£ qua c√°c b∆∞·ªõc l√†m s·∫°ch c∆° b·∫£n (x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, chu·∫©n h√≥a ƒë·ªãnh d·∫°ng...). Xem th√™m ·ªü m·ª•c ki·ªÉm tra d·ªØ li·ªáu thi·∫øu ·ªü tr√™n.
            * **M·ª•c ti√™u ƒë·ªì √°n:** X√¢y d·ª±ng dashboard t∆∞∆°ng t√°c ƒë√°p ·ª©ng y√™u c·∫ßu m√¥n h·ªçc Tr·ª±c quan h√≥a D·ªØ li·ªáu.
                * *Y√™u c·∫ßu ch√≠nh:* D·ªØ li·ªáu VN, ƒë·ªß bi·∫øn/d√≤ng, tr·ª±c quan ph√π h·ª£p & r√µ r√†ng, li√™n k·∫øt, t∆∞∆°ng t√°c, thi·∫øt k·∫ø h·∫•p d·∫´n, ph√¢n t√≠ch s√¢u, t√≠ch h·ª£p AI.
            * **ƒêi·ªÅu h∆∞·ªõng:** S·ª≠ d·ª•ng menu b√™n tr√°i ƒë·ªÉ ch·ªçn ph·∫ßn ph√¢n t√≠ch.
            * **L∆∞u √Ω:** Ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p.
            """)
    elif selected_page == page_options[1]:
        st.title("üìä Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng Chung")
        df_display = st.session_state.df_filtered
        if df_display is None or df_display.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üìà Ph√¢n t√≠ch theo Ng√†nh Ngh·ªÅ")
                tab_cat_count, tab_cat_salary = st.tabs(["S·ªë l∆∞·ª£ng tin", "Ph√¢n b·ªë l∆∞∆°ng"])
                category_counts = df_display['primary_category'].value_counts().reset_index()
                category_counts.columns = ['Ng√†nh ngh·ªÅ', 'S·ªë l∆∞·ª£ng tin']
                with tab_cat_count:
                    st.markdown("##### S·ªë l∆∞·ª£ng tin tuy·ªÉn d·ª•ng theo ng√†nh")
                    top_n_cat = st.slider("Ch·ªçn Top N ng√†nh ngh·ªÅ:", 5, min(30, len(category_counts)), 15, key='slider_cat_count_market')
                    if not category_counts.empty:
                        fig_cat_bar = px.bar(category_counts.head(top_n_cat), x='S·ªë l∆∞·ª£ng tin', y='Ng√†nh ngh·ªÅ', orientation='h', title=f'Top {top_n_cat} Ng√†nh Ngh·ªÅ Nhi·ªÅu Tin Nh·∫•t', text_auto=True, color='S·ªë l∆∞·ª£ng tin', color_continuous_scale=px.colors.sequential.Blues)
                        fig_cat_bar.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(400, top_n_cat*25), showlegend=False, uniformtext_minsize=8, uniformtext_mode='hide')
                        fig_cat_bar.update_traces(textposition='outside')
                        st.plotly_chart(fig_cat_bar, use_container_width=True)
                    else:
                        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ng√†nh ngh·ªÅ.")
                with tab_cat_salary:
                    st.markdown("##### Ph√¢n b·ªë l∆∞∆°ng t·ªëi thi·ªÉu theo ng√†nh")
                    if 'min_salary_mil_vnd' in df_display.columns and df_display['min_salary_mil_vnd'].notna().any():
                        top_categories_list = category_counts.head(top_n_cat)['Ng√†nh ngh·ªÅ'].tolist()
                        df_plot_cat_salary = df_display[df_display['primary_category'].isin(top_categories_list)].dropna(subset=['min_salary_mil_vnd'])
                        if not df_plot_cat_salary.empty:
                            fig_cat_box = px.box(df_plot_cat_salary, x='min_salary_mil_vnd', y='primary_category', title=f'Ph√¢n B·ªë L∆∞∆°ng T·ªëi Thi·ªÉu Top {top_n_cat} Ng√†nh', labels={'min_salary_mil_vnd': 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)', 'primary_category': 'Ng√†nh Ngh·ªÅ'}, points="outliers", color='primary_category', color_discrete_sequence=px.colors.qualitative.Pastel)
                            fig_cat_box.update_layout(yaxis={'categoryorder':'median ascending'}, height=max(400, top_n_cat*30), showlegend=False)
                            st.plotly_chart(fig_cat_box, use_container_width=True)
                            st.caption("Bi·ªÉu ƒë·ªì Boxplot: ƒê∆∞·ªùng gi·ªØa l√† trung v·ªã, h·ªôp l√† kho·∫£ng t·ª© ph√¢n v·ªã (IQR), c√°c ƒëi·ªÉm l√† outliers.")
                        else:
                            st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu l∆∞∆°ng cho ng√†nh ƒë√£ ch·ªçn.")
                    else:
                        st.warning("Thi·∫øu d·ªØ li·ªáu l∆∞∆°ng t·ªëi thi·ªÉu.")
            with col2:
                st.subheader("üìç Ph√¢n t√≠ch theo ƒê·ªãa ƒêi·ªÉm")
                tab_loc_count, tab_loc_salary = st.tabs(["S·ªë l∆∞·ª£ng tin", "Ph√¢n b·ªë l∆∞∆°ng"])
                location_counts = df_display['primary_location'].value_counts().reset_index()
                location_counts.columns = ['ƒê·ªãa ƒëi·ªÉm', 'S·ªë l∆∞·ª£ng tin']
                with tab_loc_count:
                    st.markdown("##### S·ªë l∆∞·ª£ng tin tuy·ªÉn d·ª•ng theo ƒë·ªãa ƒëi·ªÉm")
                    top_n_loc = st.slider("Ch·ªçn Top N ƒë·ªãa ƒëi·ªÉm:", 5, min(30, len(location_counts)), 15, key='slider_loc_count_market')
                    if not location_counts.empty:
                        fig_loc_bar = px.bar(location_counts.head(top_n_loc), x='S·ªë l∆∞·ª£ng tin', y='ƒê·ªãa ƒëi·ªÉm', orientation='h', title=f'Top {top_n_loc} ƒê·ªãa ƒêi·ªÉm Nhi·ªÅu Tin Nh·∫•t', text_auto=True, color='S·ªë l∆∞·ª£ng tin', color_continuous_scale=px.colors.sequential.Greens)
                        fig_loc_bar.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(400, top_n_loc*25), showlegend=False, uniformtext_minsize=8, uniformtext_mode='hide')
                        fig_loc_bar.update_traces(textposition='outside')
                        st.plotly_chart(fig_loc_bar, use_container_width=True)
                    else:
                        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªãa ƒëi·ªÉm.")
                with tab_loc_salary:
                    st.markdown("##### Ph√¢n b·ªë l∆∞∆°ng t·ªëi thi·ªÉu theo ƒë·ªãa ƒëi·ªÉm")
                    if 'min_salary_mil_vnd' in df_display.columns and df_display['min_salary_mil_vnd'].notna().any():
                        top_locations_list = location_counts.head(top_n_loc)['ƒê·ªãa ƒëi·ªÉm'].tolist()
                        df_plot_loc_salary = df_display[df_display['primary_location'].isin(top_locations_list)].dropna(subset=['min_salary_mil_vnd'])
                        if not df_plot_loc_salary.empty:
                            fig_loc_box = px.box(df_plot_loc_salary, x='min_salary_mil_vnd', y='primary_location', title=f'Ph√¢n B·ªë L∆∞∆°ng T·ªëi Thi·ªÉu Top {top_n_loc} ƒê·ªãa ƒêi·ªÉm', labels={'min_salary_mil_vnd': 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)', 'primary_location': 'ƒê·ªãa ƒêi·ªÉm'}, points="outliers", color='primary_location', color_discrete_sequence=px.colors.qualitative.Set2)
                            fig_loc_box.update_layout(yaxis={'categoryorder':'median ascending'}, height=max(400, top_n_loc*30), showlegend=False)
                            st.plotly_chart(fig_loc_box, use_container_width=True)
                            st.caption("Bi·ªÉu ƒë·ªì Boxplot: ƒê∆∞·ªùng gi·ªØa l√† trung v·ªã, h·ªôp l√† kho·∫£ng t·ª© ph√¢n v·ªã (IQR), c√°c ƒëi·ªÉm l√† outliers.")
                        else:
                            st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu l∆∞∆°ng cho ƒë·ªãa ƒëi·ªÉm ƒë√£ ch·ªçn.")
                    else:
                        st.warning("Thi·∫øu d·ªØ li·ªáu l∆∞∆°ng t·ªëi thi·ªÉu.")
            st.markdown("---")
            st.subheader("üìä Ph√¢n B·ªë Ng√†nh Ngh·ªÅ Theo ƒê·ªãa ƒêi·ªÉm (Bi·ªÉu ƒë·ªì c·ªôt ch·ªìng)")
            location_counts_agg = df_display['primary_location'].value_counts()
            category_counts_agg = df_display['primary_category'].value_counts()
            top_n_loc_stack = st.slider("Ch·ªçn Top N ƒë·ªãa ƒëi·ªÉm cho bi·ªÉu ƒë·ªì:", 3, min(20, len(location_counts_agg)), 8, key='slider_loc_stack_v2_market')
            top_n_cat_stack = st.slider("Ch·ªçn Top N ng√†nh ngh·ªÅ ƒë·ªÉ hi·ªÉn th·ªã chi ti·∫øt:", 3, min(20, len(category_counts_agg)), 10, key='slider_cat_stack_v2_market')
            top_loc_list_stack = location_counts_agg.head(top_n_loc_stack).index.tolist()
            top_cat_list_stack = category_counts_agg.head(top_n_cat_stack).index.tolist()
            df_stack_data_loc_filtered = df_display[df_display['primary_location'].isin(top_loc_list_stack)].copy()
            df_stack_data_loc_filtered['category_display'] = df_stack_data_loc_filtered['primary_category'].apply(
                lambda x: x if x in top_cat_list_stack else 'Ng√†nh Kh√°c'
            )
            all_display_categories = top_cat_list_stack + ['Ng√†nh Kh√°c']
            df_stack_data_loc_filtered['category_display'] = pd.Categorical(df_stack_data_loc_filtered['category_display'], categories=all_display_categories, ordered=True)
            location_category_counts_stack = df_stack_data_loc_filtered.groupby(['primary_location', 'category_display'], observed=False).size().reset_index(name='count')
            if not location_category_counts_stack.empty:
                loc_order = location_category_counts_stack.groupby('primary_location', observed=False)['count'].sum().sort_values(ascending=False).index
                location_category_counts_stack['primary_location'] = pd.Categorical(location_category_counts_stack['primary_location'], categories=loc_order, ordered=True)
                location_category_counts_stack = location_category_counts_stack.sort_values(['primary_location', 'category_display'])
                color_map = {cat: color for cat, color in zip(top_cat_list_stack, px.colors.qualitative.Pastel)}
                color_map['Ng√†nh Kh√°c'] = '#AAAAAA'
                fig_stacked_bar = px.bar(location_category_counts_stack, x='primary_location', y='count', color='category_display', title=f'Ph√¢n B·ªë Top {top_n_cat_stack} Ng√†nh (+ Ng√†nh Kh√°c) t·∫°i Top {top_n_loc_stack} ƒê·ªãa ƒêi·ªÉm', labels={'primary_location': 'ƒê·ªãa ƒêi·ªÉm', 'count': 'S·ªë L∆∞·ª£ng Tin Tuy·ªÉn D·ª•ng', 'category_display': 'Ng√†nh Ngh·ªÅ'}, height=600, color_discrete_map=color_map, custom_data=['category_display'])
                fig_stacked_bar.update_layout(xaxis={'categoryorder':'total descending'}, legend_title_text='Ng√†nh Ngh·ªÅ')
                fig_stacked_bar.update_traces(hovertemplate="<b>ƒê·ªãa ƒëi·ªÉm:</b> %{x}<br><b>Ng√†nh:</b> %{customdata[0]}<br><b>S·ªë l∆∞·ª£ng:</b> %{y}<extra></extra>")
                st.plotly_chart(fig_stacked_bar, use_container_width=True)
                st.caption("M·ªói c·ªôt l√† m·ªôt ƒë·ªãa ƒëi·ªÉm. C√°c m√†u kh√°c nhau th·ªÉ hi·ªán s·ªë l∆∞·ª£ng tin c·ªßa Top N ng√†nh v√† nh√≥m 'Ng√†nh Kh√°c'.")
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu giao nhau gi·ªØa Top N ƒë·ªãa ƒëi·ªÉm v√† Top N ng√†nh ngh·ªÅ ƒë√£ ch·ªçn ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì c·ªôt ch·ªìng.")
    elif selected_page == page_options[2]:
        st.title("üí∞ Ph√¢n T√≠ch L∆∞∆°ng & Kinh Nghi·ªám")
        df_display = st.session_state.df_filtered
        if df_display is None or df_display.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            salary_col = 'min_salary_mil_vnd'
            exp_col = 'min_experience_years'
            if salary_col not in df_display.columns or df_display[salary_col].isnull().all():
                st.error(f"Thi·∫øu d·ªØ li·ªáu c·ªôt l∆∞∆°ng '{salary_col}' ƒë·ªÉ ph√¢n t√≠ch.")
            elif exp_col not in df_display.columns or df_display[exp_col].isnull().all():
                st.error(f"Thi·∫øu d·ªØ li·ªáu c·ªôt kinh nghi·ªám '{exp_col}' ƒë·ªÉ ph√¢n t√≠ch.")
            else:
                st.subheader("Ph√¢n B·ªë M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu")
                fig_hist_min_sal = px.histogram(df_display.dropna(subset=[salary_col]), x=salary_col, nbins=50, title='Ph√¢n B·ªë M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu (Tri·ªáu VND)', labels={salary_col: 'M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu (Tri·ªáu VND)'}, marginal="box")
                fig_hist_min_sal.update_layout(bargap=0.1)
                st.plotly_chart(fig_hist_min_sal, use_container_width=True)
                st.subheader("M·ªëi Quan H·ªá Gi·ªØa L∆∞∆°ng v√† Kinh Nghi·ªám")
                col_scatter, col_box = st.columns(2)
                df_analysis = df_display.dropna(subset=[exp_col, salary_col]).copy()
                with col_scatter:
                    st.markdown("##### Scatter Plot L∆∞∆°ng vs. Kinh Nghi·ªám")
                    if not df_analysis.empty:
                        color_options_scatter = {'primary_category': 'Ng√†nh Ngh·ªÅ', 'primary_location': 'ƒê·ªãa ƒêi·ªÉm', None: 'Kh√¥ng t√¥ m√†u'}
                        selected_color_scatter = st.selectbox("T√¥ m√†u ƒëi·ªÉm theo:", list(color_options_scatter.keys()), format_func=lambda x: color_options_scatter[x], key='scatter_color_exp_salary')
                        fig_scatter = px.scatter(df_analysis, x=exp_col, y=salary_col, title='L∆∞∆°ng T·ªëi Thi·ªÉu theo Kinh Nghi·ªám', labels={exp_col: 'Kinh Nghi·ªám T·ªëi Thi·ªÉu (NƒÉm)', salary_col: 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)'}, color=selected_color_scatter, hover_name='job_title', opacity=0.6, trendline="ols", trendline_scope="overall", trendline_color_override="darkblue", height=500)
                        fig_scatter.update_layout(legend_title_text=color_options_scatter.get(selected_color_scatter, ''))
                        st.plotly_chart(fig_scatter, use_container_width=True)
                        st.caption("M·ªói ƒëi·ªÉm l√† m·ªôt tin tuy·ªÉn d·ª•ng. ƒê∆∞·ªùng m√†u xanh ƒë·∫≠m l√† ƒë∆∞·ªùng xu h∆∞·ªõng t·ªïng th·ªÉ.")
                    else:
                        st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu cho scatter plot.")
                with col_box:
                    st.markdown("##### Box Plot L∆∞∆°ng theo Nh√≥m Kinh Nghi·ªám")
                    if not df_analysis.empty:
                        max_exp_val_box = df_analysis[exp_col].max()
                        if max_exp_val_box <= 5:
                            bins = list(range(-1, int(max_exp_val_box) + 1))
                            labels = [f'{i} nƒÉm' for i in range(int(max_exp_val_box) + 1)]
                        else:
                            bins = [-1, 0, 1, 2, 3, 4, 5, 10, max_exp_val_box]
                            labels = ['0 nƒÉm', '1 nƒÉm', '2 nƒÉm', '3 nƒÉm', '4 nƒÉm', '5 nƒÉm', '6-10 nƒÉm', '10+ nƒÉm']
                            if max_exp_val_box <= 10:
                                bins = bins[:-1]
                                labels = labels[:-1]
                                if max_exp_val_box <= 5:
                                    bins = bins[:-1]
                                    labels = labels[:-1]
                        if len(bins) > 1:
                            try:
                                df_analysis['experience_group'] = pd.cut(df_analysis[exp_col], bins=bins, labels=labels, right=True)
                                df_plot_box = df_analysis.dropna(subset=['experience_group'])
                                if not df_plot_box.empty:
                                    fig_box_exp = px.box(df_plot_box, x='experience_group', y=salary_col, title='Ph√¢n B·ªë L∆∞∆°ng theo Nh√≥m Kinh Nghi·ªám', labels={'experience_group': 'Nh√≥m Kinh Nghi·ªám', salary_col: 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)'}, points="outliers", color='experience_group', color_discrete_sequence=px.colors.qualitative.Bold, height=500)
                                    fig_box_exp.update_layout(showlegend=False)
                                    st.plotly_chart(fig_box_exp, use_container_width=True)
                                else:
                                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi ph√¢n nh√≥m kinh nghi·ªám.")
                            except Exception as e:
                                st.warning(f"L·ªói khi ph√¢n nh√≥m kinh nghi·ªám: {e}. Hi·ªÉn th·ªã theo t·ª´ng nƒÉm (<=10):")
                                df_plot_box_fb = df_analysis[df_analysis[exp_col] <= 10]
                                if not df_plot_box_fb.empty:
                                    fig_box_exp_fb = px.box(df_plot_box_fb, x=exp_col, y=salary_col, title='Ph√¢n B·ªë L∆∞∆°ng theo Kinh Nghi·ªám (T·ª´ng nƒÉm <= 10)', labels={exp_col: 'Kinh Nghi·ªám (NƒÉm)', salary_col: 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)'}, points="outliers")
                                    fig_box_exp_fb.update_xaxes(type='category')
                                    st.plotly_chart(fig_box_exp_fb, use_container_width=True)
                                else:
                                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu kinh nghi·ªám <= 10 nƒÉm.")
                        else:
                            st.info("Kh√¥ng ƒë·ªß kho·∫£ng kinh nghi·ªám ƒë·ªÉ ph√¢n nh√≥m.")
                    else:
                        st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu cho box plot l∆∞∆°ng theo kinh nghi·ªám.")
                st.subheader("Xu H∆∞·ªõng L∆∞∆°ng Theo Kinh Nghi·ªám")
                st.markdown('<div class="section-title">Bi·ªÉu ƒê·ªì Xu H∆∞·ªõng</div>', unsafe_allow_html=True)
                grouped = df_display.groupby("min_experience_years")[["min_salary_mil_vnd", "max_salary_mil_vnd"]].mean().reset_index()
                if grouped.empty:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì xu h∆∞·ªõng.")
                else:
                    fig, ax = plt.subplots(figsize=(12, 7))
                    sns.lineplot(x="min_experience_years", y="min_salary_mil_vnd", data=grouped, label="M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu", ax=ax, color=PALETTE[0])
                    sns.lineplot(x="min_experience_years", y="max_salary_mil_vnd", data=grouped, label="M·ª©c L∆∞∆°ng T·ªëi ƒêa", ax=ax, color=PALETTE[1])
                    ax.set_title("M·ª©c L∆∞∆°ng Theo Kinh Nghi·ªám (Bi·ªÉu ƒê·ªì ƒê∆∞·ªùng)", fontsize=14, pad=15)
                    ax.set_xlabel("S·ªë NƒÉm Kinh Nghi·ªám T·ªëi Thi·ªÉu", fontsize=12)
                    ax.set_ylabel("M·ª©c L∆∞∆°ng (Tri·ªáu VND)", fontsize=12)
                    ax.legend(title="Lo·∫°i L∆∞∆°ng")
                    plt.grid(True, linestyle='--', alpha=0.7)
                    plt.tight_layout()
                    st.pyplot(fig)
                    pdf_buffer = save_fig_to_pdf(fig)
                    st.download_button(
                        label="üì• L∆∞u Bi·ªÉu ƒê·ªì D∆∞·ªõi D·∫°ng PDF",
                        data=pdf_buffer,
                        file_name="LineChart_MucLuong_KinhNghiem.pdf",
                        mime="application/pdf"
                    )
                st.markdown("---")
                st.subheader("üìù Nh·∫≠n X√©t")
                st.markdown("""
                * **Ph√¢n b·ªë l∆∞∆°ng:** Bi·ªÉu ƒë·ªì histogram th∆∞·ªùng cho th·∫•y l∆∞∆°ng t·∫≠p trung ·ªü m·ª©c th·∫•p ƒë·∫øn trung b√¨nh v√† c√≥ m·ªôt s·ªë gi√° tr·ªã r·∫•t cao (l·ªách ph·∫£i).
                * **L∆∞∆°ng & Kinh nghi·ªám:** C√≥ xu h∆∞·ªõng l∆∞∆°ng tƒÉng theo kinh nghi·ªám, nh∆∞ng m·ª©c ƒë·ªô tƒÉng v√† s·ª± bi·∫øn ƒë·ªông kh√°c nhau t√πy ng√†nh ngh·ªÅ v√† ƒë·ªãa ƒëi·ªÉm.
                * **Xu h∆∞·ªõng l∆∞∆°ng:** Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho th·∫•y m·ª©c l∆∞∆°ng trung b√¨nh (t·ªëi thi·ªÉu v√† t·ªëi ƒëa) c√≥ xu h∆∞·ªõng tƒÉng theo s·ªë nƒÉm kinh nghi·ªám, v·ªõi m·ª©c l∆∞∆°ng t·ªëi ƒëa th∆∞·ªùng cao h∆°n ƒë√°ng k·ªÉ ·ªü c√°c m·ª©c kinh nghi·ªám cao.
                """)
    elif selected_page == page_options[3]:
        st.title("üõ†Ô∏è Ph√¢n T√≠ch K·ªπ NƒÉng Y√™u C·∫ßu")
        df_display = st.session_state.df_filtered
        if df_display is None or df_display.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            req_col = 'job_requirements'
            if req_col not in df_display.columns or df_display[req_col].isnull().all():
                st.error(f"Thi·∫øu d·ªØ li·ªáu c·ªôt '{req_col}' ƒë·ªÉ ph√¢n t√≠ch k·ªπ nƒÉng.")
            else:
                st.subheader("K·ªπ NƒÉng Ph·ªï Bi·∫øn Nh·∫•t")
                num_display_skills = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng k·ªπ nƒÉng h√†ng ƒë·∫ßu:", 10, 50, 20, key='slider_skills_page')
                requirements_text = df_display[req_col]
                if not requirements_text.empty:
                    with st.spinner("ƒêang tr√≠ch xu·∫•t v√† ph√¢n t√≠ch k·ªπ nƒÉng..."):
                        skills_df, full_text_req = extract_skills_from_requirements(requirements_text, num_display_skills)
                    if not skills_df.empty:
                        col_bar, col_cloud = st.columns([0.6, 0.4])
                        with col_bar:
                            st.markdown(f"##### Top {num_display_skills} K·ªπ NƒÉng Ph·ªï Bi·∫øn")
                            skills_df = skills_df.astype({'K·ªπ nƒÉng': 'object'})  # Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu
                            fig_skills = px.bar(skills_df, x='S·ªë l·∫ßn xu·∫•t hi·ªán', y='K·ªπ nƒÉng', orientation='h', title=f'Top {num_display_skills} K·ªπ NƒÉng Ph·ªï Bi·∫øn', text='S·ªë l·∫ßn xu·∫•t hi·ªán', color='S·ªë l·∫ßn xu·∫•t hi·ªán', color_continuous_scale=px.colors.sequential.Viridis)
                            fig_skills.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(400, num_display_skills*20), showlegend=False, uniformtext_minsize=8, uniformtext_mode='hide')
                            fig_skills.update_traces(textposition='outside')
                            st.plotly_chart(fig_skills, use_container_width=True)
                        with col_cloud:
                            st.markdown("##### Word Cloud K·ªπ NƒÉng")
                            try:
                                skill_frequencies = {skill: count for skill, count in skills_df.values}
                                if skill_frequencies:
                                    wordcloud = WordCloud(width=800, height=600, mode="RGBA", background_color=None, max_words=100, colormap='viridis', collocations=False, contour_width=1, contour_color='steelblue').generate_from_frequencies(skill_frequencies)
                                    fig_cloud, ax = plt.subplots(figsize=(10, 7))
                                    ax.imshow(wordcloud, interpolation='bilinear')
                                    ax.axis('off')
                                    st.pyplot(fig_cloud)
                                    st.caption("K√≠ch th∆∞·ªõc ch·ªØ th·ªÉ hi·ªán t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa k·ªπ nƒÉng.")
                                else:
                                    st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu t·∫°o Word Cloud.")
                            except ImportError:
                                st.warning("Vui l√≤ng c√†i ƒë·∫∑t th∆∞ vi·ªán `wordcloud` v√† `matplotlib` ƒë·ªÉ xem Word Cloud.")
                            except Exception as e:
                                st.warning(f"L·ªói t·∫°o Word Cloud: {e}")
                    else:
                        st.info("Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng n√†o (theo danh s√°ch keywords) trong d·ªØ li·ªáu ƒë√£ l·ªçc.")
                else:
                    st.info("Kh√¥ng c√≥ y√™u c·∫ßu c√¥ng vi·ªác n√†o trong d·ªØ li·ªáu ƒë√£ l·ªçc.")
                st.markdown("---")
                st.subheader("üìù Nh·∫≠n X√©t")
                st.markdown("""
                * Bi·ªÉu ƒë·ªì c·ªôt v√† Word Cloud gi√∫p x√°c ƒë·ªãnh c√°c k·ªπ nƒÉng ƒë∆∞·ª£c y√™u c·∫ßu nhi·ªÅu nh·∫•t.
                * **Quan tr·ªçng:** K·∫øt qu·∫£ ph·ª• thu·ªôc l·ªõn v√†o danh s√°ch `skills_keywords` trong code. ƒê√£ r√† so√°t v√† b·ªï sung c√°c k·ªπ nƒÉng li√™n quan!
                """)
    elif selected_page == page_options[4]:
        st.title("ü§ñ D·ª± ƒêo√°n L∆∞∆°ng T·ªëi Thi·ªÉu (ML)")
        st.markdown("S·ª≠ d·ª•ng m√¥ h√¨nh Machine Learning (Random Forest) ƒë·ªÉ d·ª± ƒëo√°n m·ª©c l∆∞∆°ng t·ªëi thi·ªÉu d·ª±a tr√™n kinh nghi·ªám, ng√†nh ngh·ªÅ v√† ƒë·ªãa ƒëi·ªÉm.")
        df_display = st.session_state.df_filtered
        model_features = ['min_experience_years', 'primary_category', 'primary_location']
        target = 'min_salary_mil_vnd'
        required_model_cols = model_features + [target]
        min_records_threshold = 50
        if df_display is None or df_display.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
        else:
            missing_model_cols = [col for col in required_model_cols if col not in df_display.columns]
            if missing_model_cols:
                st.error(f"Thi·∫øu c√°c c·ªôt c·∫ßn thi·∫øt cho m√¥ h√¨nh AI: {', '.join(missing_model_cols)}")
            else:
                df_model_data = df_display[required_model_cols].copy().dropna()
                num_valid_records = df_model_data.shape[0]
                st.info(f"S·ªë l∆∞·ª£ng b·∫£n ghi h·ª£p l·ªá (ƒë·ªß d·ªØ li·ªáu cho c√°c c·ªôt: {', '.join(required_model_cols)}) sau khi l·ªçc: **{num_valid_records}**")
                if num_valid_records < min_records_threshold:
                    st.error(f"S·ªë l∆∞·ª£ng b·∫£n ghi h·ª£p l·ªá ({num_valid_records}) th·∫•p h∆°n ng∆∞·ª°ng t·ªëi thi·ªÉu ({min_records_threshold}). Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh ƒë√°ng tin c·∫≠y.")
                    st.markdown("**G·ª£i √Ω:** Th·ª≠ n·ªõi l·ªèng c√°c b·ªô l·ªçc d·ªØ li·ªáu ·ªü sidebar.")
                    st.session_state.model_results = None
                    st.session_state.model_metrics = {}
                    st.session_state.model_pipeline = None
                else:
                    col_train_btn, col_model_status = st.columns([0.3, 0.7])
                    # with col_train_btn:
                    #     if st.button("üîÑ Hu·∫•n luy·ªán/C·∫≠p nh·∫≠t m√¥ h√¨nh"):
                    #         st.session_state.model_results = None
                    #         st.session_state.model_metrics = {}
                    #         st.session_state.model_pipeline = None
                    #         st.info("ƒê√£ x√≥a m√¥ h√¨nh c≈©. ƒêang chu·∫©n b·ªã hu·∫•n luy·ªán l·∫°i...")
                    if st.session_state.model_pipeline is None:
                        with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi {num_valid_records} b·∫£n ghi..."):
                            results_df, rmse, mae, r2, oob = train_salary_model(df_model_data)
                            if results_df is not None:
                                st.session_state.model_results = results_df
                                st.session_state.model_metrics = {'RMSE': rmse, 'MAE': mae, 'R2 Score': r2, 'OOB Score': oob}
                                st.success(f"Hu·∫•n luy·ªán m√¥ h√¨nh th√†nh c√¥ng tr√™n {num_valid_records} b·∫£n ghi!")
                            else:
                                st.session_state.model_pipeline = None
                    else:
                        with col_model_status:
                            if st.session_state.model_metrics:
                                metrics = st.session_state.model_metrics
                                st.success(f"‚úîÔ∏è M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (R2: {metrics.get('R2 Score', 0):.3f}).")
                            else:
                                st.success("‚úîÔ∏è M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán.")
                    if st.session_state.model_pipeline is not None and st.session_state.model_results is not None:
                        st.subheader("ƒê√°nh Gi√° M√¥ H√¨nh")
                        metrics = st.session_state.model_metrics
                        oob_score_val = metrics.get('OOB Score')
                        oob_text = f"(OOB: {oob_score_val:.3f})" if oob_score_val else ""
                        m_col1, m_col2, m_col3 = st.columns(3)
                        m_col1.metric("RMSE (L·ªói TB)", f"{metrics.get('RMSE', 0):.2f} Tr")
                        m_col2.metric("MAE (L·ªói Tuy·ªát ƒë·ªëi TB)", f"{metrics.get('MAE', 0):.2f} Tr")
                        m_col3.metric(f"R2 Score {oob_text}", f"{metrics.get('R2 Score', 0):.3f}")
                        st.caption(f"ƒê√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra (20% c·ªßa {num_valid_records}). OOB Score l√† ƒë·ªô ch√≠nh x√°c ∆∞·ªõc t√≠nh tr√™n d·ªØ li·ªáu ch∆∞a th·∫•y khi hu·∫•n luy·ªán RF.")
                        results_df = st.session_state.model_results
                        results_df = results_df.astype({'Th·ª±c t·∫ø': 'float64', 'D·ª± ƒëo√°n': 'float64'})
                        fig_pred = px.scatter(results_df, x='Th·ª±c t·∫ø', y='D·ª± ƒëo√°n', title='K·∫øt Qu·∫£ D·ª± ƒêo√°n vs. Th·ª±c T·∫ø', labels={'Th·ª±c t·∫ø': 'L∆∞∆°ng Th·ª±c T·∫ø (Tr VND)', 'D·ª± ƒëo√°n': 'L∆∞∆°ng D·ª± ƒêo√°n (Tr VND)'}, opacity=0.7, height=500)
                        min_val = min(results_df['Th·ª±c t·∫ø'].min(), results_df['D·ª± ƒëo√°n'].min()) * 0.95
                        max_val = max(results_df['Th·ª±c t·∫ø'].max(), results_df['D·ª± ƒëo√°n'].max()) * 1.05
                        fig_pred.add_shape(type="line", x0=min_val, y0=min_val, x1=max_val, y1=max_val, line=dict(color="red", width=2, dash="dash"), name="L√Ω t∆∞·ªüng")
                        fig_pred.update_xaxes(range=[min_val, max_val])
                        fig_pred.update_yaxes(range=[min_val, max_val])
                        st.plotly_chart(fig_pred, use_container_width=True)
                        st.subheader("Th·ª≠ D·ª± ƒêo√°n L∆∞∆°ng")
                        all_categories_model = sorted(st.session_state.df_jobs['primary_category'].astype(str).unique())
                        all_locations_model = sorted(st.session_state.df_jobs['primary_location'].astype(str).unique())
                        with st.form("prediction_form"):
                            pred_exp = st.number_input("S·ªë nƒÉm kinh nghi·ªám:", min_value=0.0, max_value=50.0, value=2.0, step=0.5)
                            default_cat_index = all_categories_model.index(st.session_state.filters['category'][0]) if st.session_state.filters.get('category') and st.session_state.filters['category'][0] in all_categories_model else 0
                            default_loc_index = all_locations_model.index(st.session_state.filters['location'][0]) if st.session_state.filters.get('location') and st.session_state.filters['location'][0] in all_locations_model else 0
                            pred_cat = st.selectbox("Ng√†nh ngh·ªÅ:", options=all_categories_model, index=default_cat_index)
                            pred_loc = st.selectbox("ƒê·ªãa ƒëi·ªÉm:", options=all_locations_model, index=default_loc_index)
                            submitted = st.form_submit_button("D·ª± ƒëo√°n m·ª©c l∆∞∆°ng t·ªëi thi·ªÉu")
                            if submitted:
                                input_data = pd.DataFrame({'min_experience_years': [pred_exp], 'primary_category': [pred_cat], 'primary_location': [pred_loc]})
                                try:
                                    prediction = st.session_state.model_pipeline.predict(input_data)
                                    st.success(f"M·ª©c l∆∞∆°ng t·ªëi thi·ªÉu d·ª± ƒëo√°n: **{prediction[0]:.1f} Tri·ªáu VND**")
                                except Exception as e:
                                    st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")
                        st.markdown("---")
                        st.subheader("üìù Nh·∫≠n X√©t")
                        st.markdown(f"""
                        * **M√¥ h√¨nh:** Random Forest d·ª± ƒëo√°n l∆∞∆°ng d·ª±a tr√™n kinh nghi·ªám, ng√†nh ngh·ªÅ, ƒë·ªãa ƒëi·ªÉm.
                        * **ƒê√°nh gi√°:** C√°c ch·ªâ s·ªë RMSE ({metrics.get('RMSE', 0):.2f} Tr), MAE ({metrics.get('MAE', 0):.2f} Tr), v√† R2 Score ({metrics.get('R2 Score', 0):.3f}) cho th·∫•y m·ª©c ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm tra. OOB score ({oob_score_val:.3f} n·∫øu c√≥) l√† m·ªôt ∆∞·ªõc t√≠nh kh√°c v·ªÅ hi·ªáu su·∫•t.
                        * **H·∫°n ch·∫ø:** K·∫øt qu·∫£ ch·ªâ mang t√≠nh tham kh·∫£o, ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu, b·ªô l·ªçc hi·ªán t·∫°i v√† s·ª± ƒë∆°n gi·∫£n c·ªßa m√¥ h√¨nh (ch·ªâ d√πng 3 y·∫øu t·ªë).
                        """)
                    elif st.session_state.model_pipeline is None and num_valid_records >= min_records_threshold:
                        st.info("Nh·∫•n n√∫t 'Hu·∫•n luy·ªán/C·∫≠p nh·∫≠t m√¥ h√¨nh' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    elif selected_page == page_options[5]:
        st.header("üìà Th·ªëng K√™ M√¥ T·∫£")
        df = st.session_state.df_filtered
        if df is None or df.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            st.markdown("""
                <style>
                .section-title {
                    font-size: 24px;
                    font-weight: 500;
                    margin-bottom: 15px;
                    color: #333333;
                }
                .chart-title {
                    font-size: 18px;
                    font-weight: bold;
                    color: #FF851B;
                    margin-bottom: 10px;
                }
                .debug-expander {
                    background-color: #f9f9f9;
                    padding: 10px;
                    border-radius: 5px;
                }
                </style>
            """, unsafe_allow_html=True)
            tab1, tab2, tab3 = st.tabs(["üìä Th√¥ng Tin D·ªØ Li·ªáu", "üìà Ph√¢n Ph·ªëi Bi·∫øn S·ªë", "üìâ Ph√¢n Ph·ªëi Bi·∫øn Ph√¢n Lo·∫°i"])
            with tab1:
                st.markdown('<div class="section-title">Th√¥ng Tin D·ªØ Li·ªáu</div>', unsafe_allow_html=True)
                df = df.astype({col: 'object' for col in df.columns if df[col].dtype == 'string'})
                st.dataframe(df.describe(include='all'), height=300)
            with tab2:
                st.markdown('<div class="section-title">Ph√¢n Ph·ªëi Bi·∫øn S·ªë</div>', unsafe_allow_html=True)
                numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
                num_select = st.selectbox("Ch·ªçn m·ªôt bi·∫øn s·ªë ƒë·ªÉ xem ph√¢n ph·ªëi:", numeric_cols)
                if num_select:
                    chart_type = st.radio("Ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì:", ["Histogram (v·ªõi KDE)", "Boxplot", "KDE Plot"])
                    st.markdown('<div class="chart-title">Bi·ªÉu ƒê·ªì Ph√¢n Ph·ªëi</div>', unsafe_allow_html=True)
                    fig, ax = plt.subplots(figsize=(14, 7))
                    if chart_type == "Histogram (v·ªõi KDE)":
                        sns.histplot(df[num_select].dropna(), kde=True, color=PALETTE[0], ax=ax)
                        ax.set_title(f"Ph√¢n b·ªë c·ªßa {num_select} (Histogram v·ªõi KDE)", fontsize=14, pad=15)
                    elif chart_type == "Boxplot":
                        sns.boxplot(y=df[num_select].dropna(), color=PALETTE[1], ax=ax)
                        ax.set_title(f"Ph√¢n b·ªë c·ªßa {num_select} (Boxplot)", fontsize=14, pad=15)
                    elif chart_type == "KDE Plot":
                        sns.kdeplot(df[num_select].dropna(), color=PALETTE[2], fill=True, ax=ax)
                        ax.set_title(f"Ph√¢n b·ªë c·ªßa {num_select} (KDE Plot)", fontsize=14, pad=15)
                    ax.set_xlabel(num_select, fontsize=12)
                    ax.set_ylabel('S·ªë l∆∞·ª£ng' if chart_type != "Boxplot" else '', fontsize=12)
                    plt.tight_layout()
                    st.pyplot(fig)
                    pdf_buffer = save_fig_to_pdf(fig)
                    st.download_button(
                        label="üì• L∆∞u Bi·ªÉu ƒê·ªì D∆∞·ªõi D·∫°ng PDF",
                        data=pdf_buffer,
                        file_name=f"PhanBo_{num_select}_{chart_type}.pdf",
                        mime="application/pdf"
                    )
            with tab3:
                st.markdown('<div class="section-title">Ph√¢n Ph·ªëi Bi·∫øn Ph√¢n Lo·∫°i</div>', unsafe_allow_html=True)
                st.markdown('<div class="filter-box">', unsafe_allow_html=True)
                unique_locations = df['primary_location'].dropna().unique().tolist()
                selected_locations = st.multiselect(
                    "üìç L·ªçc theo ƒë·ªãa ƒëi·ªÉm:",
                    options=unique_locations,
                    default=unique_locations,
                    key="filter_locations_categorical"
                )
                st.markdown('</div>', unsafe_allow_html=True)
                filtered_df = df.copy()
                if selected_locations:
                    filtered_df = filtered_df[filtered_df['primary_location'].isin(selected_locations)]
                if filtered_df.empty:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l·ªçc. Vui l√≤ng ch·ªçn l·∫°i ƒë·ªãa ƒëi·ªÉm.")
                else:
                    cat_cols = ['order', 'position', 'primary_category']
                    cat_select = st.selectbox("Ch·ªçn m·ªôt bi·∫øn ph√¢n lo·∫°i ƒë·ªÉ xem ph√¢n ph·ªëi:", cat_cols)
                    if cat_select:
                        grouped = filtered_df.groupby('primary_location', observed=False)[cat_select].value_counts().unstack(fill_value=0)
                        grouped.columns.name = cat_select
                        grouped.index.name = 'primary_location'
                        grouped = grouped.astype('object')
                        grouped = grouped.reindex(selected_locations)
                        grouped = grouped.sort_index(ascending=False)
                        fig, ax = plt.subplots(figsize=(20, 16))
                        grouped.plot(kind='bar', stacked=True, ax=ax, colormap='tab20')
                        ax.set_title(f"Ph√¢n Ph·ªëi '{cat_select}' Theo ƒê·ªãa ƒêi·ªÉm ƒê√£ Ch·ªçn", fontsize=16, pad=10)
                        ax.set_xlabel("ƒê·ªãa ƒëi·ªÉm", fontsize=14)
                        ax.set_ylabel("S·ªë l∆∞·ª£ng", fontsize=14)
                        plt.xticks(rotation=90, ha='right')
                        plt.tight_layout()
                        st.pyplot(fig)
                        pdf_buffer = save_fig_to_pdf(fig)
                        st.download_button(
                            label="üì• L∆∞u Bi·ªÉu ƒê·ªì D∆∞·ªõi D·∫°ng PDF",
                            data=pdf_buffer,
                            file_name=f"PhanBo_{cat_select}_TheoDiaDiem.pdf",
                            mime="application/pdf"
                        )
    elif selected_page == page_options[6]:
        st.title("üí° C·ªë v·∫•n AI (Gemini)")
        if not ai_configured_successfully:
            st.error("üö® C·∫•u h√¨nh AI th·∫•t b·∫°i ho·∫∑c thi·∫øu API Key. Vui l√≤ng ki·ªÉm tra GEMINI_API_KEY trong file .env ho·∫∑c c·∫•u h√¨nh secrets.")
            st.warning("Tab n√†y s·∫Ω kh√¥ng ho·∫°t ƒë·ªông cho ƒë·∫øn khi AI ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng.")
            st.stop()
        df_for_ai = st.session_state.get('df_jobs')
        if df_for_ai is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i l√™n ho·∫∑c ch·ªù d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.")
        else:
            st.info("Ch·ª©c nƒÉng n√†y s·ª≠ d·ª•ng Google Gemini AI ƒë·ªÉ cung c·∫•p th√¥ng tin chi ti·∫øt v√† tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu tuy·ªÉn d·ª•ng hi·ªán t·∫°i.")
            with st.expander("Xem th√¥ng tin v√† d·ªØ li·ªáu m·∫´u ƒë∆∞·ª£c cung c·∫•p cho AI", expanded=False):
                st.subheader("Th√¥ng tin t·ªïng quan v·ªÅ d·ªØ li·ªáu (cho AI)")
                dataset_info_str = get_dataset_info(df_for_ai)
                st.text_area("Dataset Info (Text):", dataset_info_str, height=300)
                st.subheader("D·ªØ li·ªáu m·∫´u (cho AI)")
                try:
                    csv_string_data = df_for_ai.to_csv(index=False, header=True, quoting=csv.QUOTE_MINIMAL)
                    data_rows_for_ai = csv_string_data.splitlines()
                    max_rows_to_feed = 500
                    data_summary_for_ai = "\\n".join(data_rows_for_ai[:max_rows_to_feed])
                    if len(data_rows_for_ai) > max_rows_to_feed:
                        data_summary_for_ai += f"\\n... (D·ªØ li·ªáu ƒë∆∞·ª£c c·∫Øt ng·∫Øn c√≤n {max_rows_to_feed} d√≤ng trong t·ªïng s·ªë {len(data_rows_for_ai)} d√≤ng)"
                    st.text_area("D·ªØ li·ªáu d·∫°ng CSV (m·ªôt ph·∫ßn) g·ª≠i cho AI:", data_summary_for_ai, height=200)
                except Exception as e:
                    st.error(f"L·ªói khi chu·∫©n b·ªã d·ªØ li·ªáu cho AI: {e}")
                    data_summary_for_ai = "Kh√¥ng c√≥ d·ªØ li·ªáu do l·ªói."
            data_context_for_ai = f"""
            Th√¥ng tin Dataset:
            {dataset_info_str}
            
            M·ªôt ph·∫ßn d·ªØ li·ªáu (CSV format):
            {data_summary_for_ai}
            """
            st.divider()
            st.subheader("üí¨ ƒê·∫∑t c√¢u h·ªèi cho AI")
            user_query = st.text_area("C√¢u h·ªèi c·ªßa b·∫°n v·ªÅ d·ªØ li·ªáu tuy·ªÉn d·ª•ng:", height=100, 
                                      placeholder="V√≠ d·ª•: C√°c k·ªπ nƒÉng n√†o ƒëang ƒë∆∞·ª£c y√™u c·∫ßu nhi·ªÅu nh·∫•t cho v·ªã tr√≠ Data Analyst? M·ª©c l∆∞∆°ng trung b√¨nh cho c√°c v·ªã tr√≠ Fresher l√† bao nhi√™u?")
            if st.button("G·ª≠i c√¢u h·ªèi cho AI", type="primary", key="ai_ask_button"):
                if not user_query:
                    st.warning("Vui l√≤ng nh·∫≠p c√¢u h·ªèi.")
                elif not ai_configured_successfully or genai_model is None:
                    st.error("AI ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh.")
                else:
                    with st.spinner("ü§ñ AI ƒëang suy nghƒ©..."):
                        feedback = generate_feedback(data_context_for_ai, user_query)
                        st.subheader("AI tr·∫£ l·ªùi:")
                        st.markdown(feedback)
elif uploaded_file is None:
    st.info("üí° Vui l√≤ng t·∫£i l√™n t·ªáp CSV qua thanh b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
st.sidebar.markdown("---")
st.sidebar.markdown(f"¬© {pd.Timestamp.now().year} - [Nh√≥m 3]")
st.sidebar.info("Dashboard ƒë∆∞·ª£c t·∫°o b·∫±ng Streamlit.")