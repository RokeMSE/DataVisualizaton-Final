# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import re
from collections import Counter
import csv
from io import BytesIO # ƒê·ªÉ d√πng cho n√∫t download
# Th∆∞ vi·ªán WordCloud (c·∫ßn c√†i ƒë·∫∑t: pip install wordcloud)
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
# Th∆∞ vi·ªán AI/ML
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor # Th·ª≠ m√¥ h√¨nh kh√°c
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib # L∆∞u/t·∫£i m√¥ h√¨nh (t√πy ch·ªçn)

# ==============================================================================
# --- 1. C·∫§U H√åNH TRANG V√Ä CSS (N·∫øu c√≥) ---
# ==============================================================================
st.set_page_config(
    page_title="Dashboard Ph√¢n T√≠ch Tuy·ªÉn D·ª•ng VN",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

sns.set_palette("colorblind")
PALETTE = ["#88CCEE", "#44AA99", "#117733", "#999933", "#DDCC77", "#CC6677", "#882255", "#AA4499"]
def save_fig_to_pdf(fig):
    buffer = BytesIO()
    fig.savefig(buffer, format='pdf', bbox_inches='tight')
    buffer.seek(0)
    return buffer
# (T√πy ch·ªçn) Th√™m CSS t√πy ch·ªânh t·∫°i ƒë√¢y n·∫øu mu·ªën
# st.markdown("""<style>...</style>""", unsafe_allow_html=True)


# ==============================================================================
# --- 2. C√ÅC H√ÄM H·ªñ TR·ª¢ ---
# ==============================================================================

# --- H√†m t·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ---
@st.cache_data(show_spinner="ƒêang t·∫£i d·ªØ li·ªáu...")
def load_data(uploaded_file):
    """T·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file CSV ƒë∆∞·ª£c t·∫£i l√™n."""
    try:
        df = pd.read_csv(
            uploaded_file,
            encoding='utf-8',
            na_values=["None", " ", "UNKNOWN", -1, 999, "NA", "N/A", "NULL", ""],
        )
        st.session_state.original_filename = uploaded_file.name # L∆∞u t√™n file g·ªëc

        # --- C√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω c∆° b·∫£n ---
        salary_cols = ['min_salary_mil_vnd', 'max_salary_mil_vnd']
        for col in salary_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            else: # T·∫°o c·ªôt n·∫øu thi·∫øu ƒë·ªÉ tr√°nh l·ªói sau n√†y
                df[col] = np.nan

        exp_cols = ['min_experience_years', 'max_experience_years']
        for col in exp_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                df[col] = df[col].clip(0, 50) # Gi·ªõi h·∫°n kinh nghi·ªám h·ª£p l√Ω
            else:
                df[col] = np.nan

        categorical_cols = ['primary_location', 'primary_category', 'position', 'order']
        for col in categorical_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).fillna('Kh√¥ng x√°c ƒë·ªãnh')
                df[col] = df[col].str.strip()
                df[col] = df[col].astype('category')
            else: # T·∫°o c·ªôt category r·ªóng n·∫øu thi·∫øu
                 df[col] = pd.Categorical(['Kh√¥ng x√°c ƒë·ªãnh'] * len(df))


        if 'job_requirements' in df.columns:
            df['job_requirements'] = df['job_requirements'].astype(str).fillna('')
        else:
             df['job_requirements'] = '' # T·∫°o c·ªôt r·ªóng n·∫øu kh√¥ng t·ªìn t·∫°i

        if 'company_title' not in df.columns:
            df['company_title'] = 'Kh√¥ng x√°c ƒë·ªãnh' # T·∫°o c·ªôt n·∫øu thi·∫øu cho KPI
        else:
             df['company_title'] = df['company_title'].astype(str).str.strip()

        if 'job_title' not in df.columns:
             df['job_title'] = 'Kh√¥ng x√°c ƒë·ªãnh'
        else:
             df['job_title'] = df['job_title'].astype(str).str.strip()


        if df.empty:
            st.error("D·ªØ li·ªáu r·ªóng sau khi ƒë·ªçc file.")
            return None

        return df

    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file CSV: {e}")
        st.exception(e) # In chi ti·∫øt l·ªói ƒë·ªÉ debug
        return None

# --- H√†m tr√≠ch xu·∫•t k·ªπ nƒÉng ---
@st.cache_data
def extract_skills_from_requirements(text_series, num_skills=30):
    """Tr√≠ch xu·∫•t v√† ƒë·∫øm t·∫ßn su·∫•t c√°c k·ªπ nƒÉng t·ª´ c·ªôt job_requirements."""
    # Danh s√°ch keywords V√ç D·ª§ - C·∫ßn ƒë∆∞·ª£c t√πy ch·ªânh v√† m·ªü r·ªông ƒë√°ng k·ªÉ
    skills_keywords = [
        # Ng√¥n ng·ªØ & Frameworks
        'python', 'java', 'sql', 'javascript', 'react', 'angular', 'vue', 'node.js','nodejs',
        'c#', '.net', 'php', 'ruby', 'swift', 'kotlin', 'android', 'ios', 'flutter', 'html', 'css',
        'typescript', 'go', 'rust', 'scala', 'perl', 'c++', ' c ', # Th√™m kho·∫£ng tr·∫Øng cho 'c'
        # Databases
        'mysql', 'postgresql', 'sql server', 'mongodb', 'oracle', 'redis', 'cassandra','nosql',
        # Cloud & DevOps
        'aws', 'azure', 'gcp', 'google cloud', 'docker', 'kubernetes','k8s', 'terraform', 'linux', 'jenkins', 'git', 'ci/cd', 'devops', 'ansible',
        # Data Science & ML/AI
        'excel', 'power bi', 'tableau', 'qlik', 'data analysis','ph√¢n t√≠ch d·ªØ li·ªáu', 'machine learning','h·ªçc m√°y', 'ai','tr√≠ tu·ªá nh√¢n t·∫°o', 'deep learning','h·ªçc s√¢u',
        'pandas', 'numpy', 'scikit-learn','sklearn', 'tensorflow', 'pytorch', 'keras', 'hadoop', 'spark', 'big data','d·ªØ li·ªáu l·ªõn','data warehouse','data mining',
        # K·ªπ nƒÉng m·ªÅm & Nghi·ªáp v·ª•
        'project management','qu·∫£n l√Ω d·ª± √°n', 'agile', 'scrum', 'communication','giao ti·∫øp', 'leadership','l√£nh ƒë·∫°o', 'teamwork','l√†m vi·ªác nh√≥m',
        'problem solving','gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ', 'critical thinking','t∆∞ duy ph·∫£n bi·ªán', 'english','ti·∫øng anh', 'japanese','ti·∫øng nh·∫≠t', 'korean','ti·∫øng h√†n', 'chinese','ti·∫øng trung',
        'marketing', 'digital marketing', 'sales','b√°n h√†ng', 'seo', 'sem', 'content', 'social media',
        'finance','t√†i ch√≠nh', 'accounting','k·∫ø to√°n', 'auditing','ki·ªÉm to√°n', 'banking','ng√¢n h√†ng',
        'hr','nh√¢n s·ª±', 'recruitment','tuy·ªÉn d·ª•ng', 'talent acquisition','c&b','payroll',
        'customer service','chƒÉm s√≥c kh√°ch h√†ng', 'support','h·ªó tr·ª£',
        # Design
        'design', 'ui', 'ux', 'photoshop', 'illustrator', 'figma', 'sketch', 'graphic design',
        # Others - Th√™m c√°c k·ªπ nƒÉng ƒë·∫∑c th√π kh√°c
        'autocad', 'revit', 'sap', 'erp', 'logistics', 'supply chain','chu·ªói cung ·ª©ng', 'teaching','gi·∫£ng d·∫°y', 'research','nghi√™n c·ª©u', 'writing','vi·∫øt l√°ch'
    ]
    text = ' '.join(text_series.astype(str).str.lower()) # ƒê·∫£m b·∫£o l√† chu·ªói v√† lowercase
    skill_counts = Counter()
    for skill in skills_keywords:
        # T√¨m ki·∫øm linh ho·∫°t h∆°n, x·ª≠ l√Ω d·∫•u c√¢u c∆° b·∫£n xung quanh t·ª´ kh√≥a
        pattern = r'(?:^|\s|[.,;!?():\'"])' + re.escape(skill).replace(r'\.', r'[\.\s-]?').replace(r'\-', r'[\s-]?') + r'(?:$|\s|[.,;!?():\'"])'
        try:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            count = sum(1 for _ in matches)
            if count > 0:
                 # Chu·∫©n h√≥a key (v√≠ d·ª•: node.js v√† nodejs v·ªÅ m·ªôt m·ªëi)
                 normalized_skill = skill.replace('\\', '').replace('.', '').replace('-', '').replace(' ', '')
                 # ∆Øu ti√™n gi·ªØ l·∫°i t√™n g·ªëc n·∫øu ƒë√£ c√≥, c·ªông d·ªìn count
                 existing_keys = [k for k in skill_counts if k.replace('.', '').replace('-', '').replace(' ', '') == normalized_skill]
                 if existing_keys:
                     # ∆Øu ti√™n key g·ªëc c√≥ v·∫ª "chu·∫©n" h∆°n (v√≠ d·ª•: gi·ªØ l·∫°i 'node.js' thay v√¨ 'nodejs')
                     chosen_key = min(existing_keys + [skill.replace('\\', '')], key=len) # ∆Øu ti√™n key ng·∫Øn h∆°n n·∫øu chu·∫©n h√≥a gi·ªëng nhau
                     skill_counts[chosen_key] += count
                     # X√≥a c√°c key chu·∫©n h√≥a gi·ªëng nhau kh√°c n·∫øu c√≥
                     for other_key in existing_keys:
                         if other_key != chosen_key and other_key in skill_counts:
                             skill_counts[chosen_key] += skill_counts.pop(other_key)

                 else:
                     skill_counts[skill.replace('\\', '')] += count
        except re.error: pass # B·ªè qua n·∫øu regex l·ªói

    top_skills = skill_counts.most_common(num_skills)
    return pd.DataFrame(top_skills, columns=['K·ªπ nƒÉng', 'S·ªë l·∫ßn xu·∫•t hi·ªán']), text

# --- H√†m hu·∫•n luy·ªán m√¥ h√¨nh d·ª± ƒëo√°n l∆∞∆°ng ---
@st.cache_resource # Cache m√¥ h√¨nh v√† preprocessor ƒë√£ hu·∫•n luy·ªán
def train_salary_model(df_train):
    """Hu·∫•n luy·ªán m√¥ h√¨nh d·ª± ƒëo√°n l∆∞∆°ng (min_salary_mil_vnd)."""
    model_features = ['min_experience_years', 'primary_category', 'primary_location']
    target = 'min_salary_mil_vnd'

    # D·ªØ li·ªáu ƒë·∫ßu v√†o ƒë√£ ƒë∆∞·ª£c dropna tr∆∞·ªõc khi g·ªçi h√†m n√†y
    X = df_train[model_features]
    y = df_train[target]

    # Chia d·ªØ li·ªáu
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Pipeline ti·ªÅn x·ª≠ l√Ω: OneHotEncode cho bi·∫øn ph√¢n lo·∫°i, gi·ªØ nguy√™n bi·∫øn s·ªë
    categorical_features = ['primary_category', 'primary_location']
    numeric_features = ['min_experience_years']

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numeric_features)
        ],
        remainder='drop'
    )

    # Ch·ªçn m√¥ h√¨nh (Random Forest c√≥ v·∫ª t·ªët h∆°n cho d·ªØ li·ªáu d·∫°ng b·∫£ng)
    model_choice = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10, min_samples_leaf=5, oob_score=True)

    # T·∫°o pipeline ho√†n ch·ªânh
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', model_choice)
    ])

    # Hu·∫•n luy·ªán
    try:
        pipeline.fit(X_train, y_train)
        # L·∫•y OOB score n·∫øu d√πng RandomForest
        oob_score = pipeline.named_steps['regressor'].oob_score_ if hasattr(pipeline.named_steps['regressor'], 'oob_score_') else None
    except Exception as e:
        st.error(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {e}")
        return None, None, None, None, None # Tr·∫£ v·ªÅ th√™m OOB score

    # ƒê√°nh gi√° tr√™n t·∫≠p test
    y_pred = pipeline.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results_df = pd.DataFrame({'Th·ª±c t·∫ø': y_test, 'D·ª± ƒëo√°n': y_pred})

    # L∆∞u pipeline v√†o state (kh√¥ng ch·ªâ model v√† preprocessor ri√™ng l·∫ª)
    st.session_state.model_pipeline = pipeline

    return results_df, rmse, mae, r2, oob_score

# --- H√†m chuy·ªÉn ƒë·ªïi dataframe sang CSV cho n√∫t download ---
@st.cache_data
def convert_df_to_csv(df):
    """Chuy·ªÉn ƒë·ªïi DataFrame th√†nh bytes CSV UTF-8."""
    return df.to_csv(index=False).encode('utf-8')


# ==============================================================================
# --- 3. KH·ªûI T·∫†O SESSION STATE ---
# ==============================================================================
if 'df_jobs' not in st.session_state:
    st.session_state.df_jobs = None          # DataFrame g·ªëc
    st.session_state.df_filtered = None     # DataFrame ƒë√£ l·ªçc
    st.session_state.original_filename = "" # T√™n file g·ªëc
    st.session_state.filters = {}           # Dict l∆∞u tr·∫°ng th√°i b·ªô l·ªçc
    st.session_state.model_results = None   # K·∫øt qu·∫£ ƒë√°nh gi√° m√¥ h√¨nh AI
    st.session_state.model_metrics = {}     # Ch·ªâ s·ªë ƒë√°nh gi√° m√¥ h√¨nh AI
    st.session_state.model_pipeline = None  # Pipeline m√¥ h√¨nh AI ƒë√£ hu·∫•n luy·ªán


# ==============================================================================
# --- 4. SIDEBAR: UPLOAD FILE V√Ä B·ªò L·ªåC ---
# ==============================================================================
st.sidebar.title("B·∫£ng ƒëi·ªÅu khi·ªÉn")
uploaded_file = st.sidebar.file_uploader(
    "üìÅ T·∫£i l√™n t·ªáp CSV",
    type=["csv"],
    help="T·∫£i l√™n file CSV ch·ª©a d·ªØ li·ªáu tuy·ªÉn d·ª•ng ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch (UTF-8)."
)

# X·ª≠ l√Ω t·∫£i file v√† l∆∞u v√†o session state
if uploaded_file is not None:
    # Ch·ªâ t·∫£i l·∫°i n·∫øu file kh√°c ho·∫∑c ch∆∞a c√≥ d·ªØ li·ªáu
    if st.session_state.df_jobs is None or st.session_state.original_filename != uploaded_file.name:
         with st.spinner("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu..."):
            st.session_state.df_jobs = load_data(uploaded_file)
            # Reset b·ªô l·ªçc v√† k·∫øt qu·∫£ model khi t·∫£i file m·ªõi
            st.session_state.filters = {}
            st.session_state.model_results = None
            st.session_state.model_metrics = {}
            st.session_state.model_pipeline = None

# Ki·ªÉm tra n·∫øu c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã b·ªô l·ªçc v√† n·ªôi dung
if st.session_state.df_jobs is not None:
    df_jobs = st.session_state.df_jobs

    
    # --- ƒêi·ªÅu h∆∞·ªõng trang gi·∫£ l·∫≠p ---
    st.sidebar.header("ƒêi·ªÅu H∆∞·ªõng")
    page_options = [
        "üè† Trang Ch·ªß & T·ªïng Quan",
        "üìä Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng",
        "üí∞ Ph√¢n T√≠ch L∆∞∆°ng & Kinh Nghi·ªám",
        "üõ†Ô∏è Ph√¢n T√≠ch K·ªπ NƒÉng",
        "ü§ñ D·ª± ƒêo√°n L∆∞∆°ng (AI)",
        "üìà Th·ªëng K√™ M√¥ T·∫£"
    ]
    selected_page = st.sidebar.radio(
        "Ch·ªçn trang:",
        page_options,
        key='page_navigation'
    )
    
    # --- B·ªô l·ªçc chung ---
    st.sidebar.header("B·ªô l·ªçc d·ªØ li·ªáu")
    # Kh√¥ng c·∫ßn l·∫•y filters t·ª´ state n·ªØa v√¨ default s·∫Ω ghi ƒë√® l√™n
    # filters = st.session_state.get('filters', {})

    # L·∫•y danh s√°ch unique v√† s·∫Øp x·∫øp
    locations = sorted(df_jobs['primary_location'].astype(str).unique())
    categories = sorted(df_jobs['primary_category'].astype(str).unique())

    # Widget l·ªçc ƒë·ªãa ƒëi·ªÉm - M·∫∂C ƒê·ªäNH CH·ªåN T·∫§T C·∫¢
    selected_location = st.sidebar.multiselect(
        'üìç Ch·ªçn ƒê·ªãa ƒëi·ªÉm:', options=locations,
        default=locations, # Default m·ªõi: ch·ªçn t·∫•t c·∫£
        key='filter_location'
    )

    # Widget l·ªçc ng√†nh ngh·ªÅ - M·∫∂C ƒê·ªäNH CH·ªåN T·∫§T C·∫¢
    selected_category = st.sidebar.multiselect(
        'üìÇ Ch·ªçn Ng√†nh ngh·ªÅ:', options=categories,
        default=categories, # Default m·ªõi: ch·ªçn t·∫•t c·∫£
        key='filter_category'
    )

    # Widget l·ªçc kinh nghi·ªám - M·∫∂C ƒê·ªäNH CH·ªåN TO√ÄN B·ªò KHO·∫¢NG
    exp_col = 'min_experience_years'
    if exp_col in df_jobs.columns and df_jobs[exp_col].notna().any():
        min_exp_val = int(df_jobs[exp_col].min(skipna=True))
        max_exp_val = int(df_jobs[exp_col].max(skipna=True))
        exp_default = (min_exp_val, max_exp_val) # Default m·ªõi: to√†n b·ªô kho·∫£ng
        selected_exp_range = st.sidebar.slider(
            '‚è≥ Kinh nghi·ªám t·ªëi thi·ªÉu (nƒÉm):', min_value=min_exp_val, max_value=max_exp_val,
            value=exp_default, key='filter_experience'
        )
    else:
        selected_exp_range = None # Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l·ªçc

    # Widget l·ªçc l∆∞∆°ng - M·∫∂C ƒê·ªäNH CH·ªåN TO√ÄN B·ªò KHO·∫¢NG
    salary_col = 'min_salary_mil_vnd'
    if salary_col in df_jobs.columns and df_jobs[salary_col].notna().any():
        min_sal_val = float(df_jobs[salary_col].min(skipna=True))
        max_sal_val = float(df_jobs[salary_col].quantile(0.99, interpolation='nearest'))
        if min_sal_val >= max_sal_val :
            max_sal_val = float(df_jobs[salary_col].max(skipna=True))
            if min_sal_val > max_sal_val: min_sal_val = max_sal_val
        sal_default = (min_sal_val, max_sal_val) # Default m·ªõi: to√†n b·ªô kho·∫£ng

        salary_median = df_jobs[salary_col].median()
        median_text = f" ({salary_median:.0f} Tr Median)" if pd.notna(salary_median) else ""

        selected_salary_range = st.sidebar.slider(
            f'üí∞ L∆∞∆°ng t·ªëi thi·ªÉu{median_text}:',
            min_value=min_sal_val, max_value=max_sal_val,
            value=sal_default, step=0.5, key='filter_salary',
            format="%.1f Tri·ªáu VND"
        )
    else:
        selected_salary_range = None # Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l·ªçc

    # L∆∞u b·ªô l·ªçc hi·ªán t·∫°i v√†o session state ƒë·ªÉ d√πng khi v·∫Ω ƒë·ªì th·ªã
    st.session_state.filters = {
        'location': selected_location,
        'category': selected_category,
        'experience': selected_exp_range,
        'salary': selected_salary_range
    }

    # --- √Åp d·ª•ng b·ªô l·ªçc ---
    # Lu√¥n √°p d·ª•ng b·ªô l·ªçc d·ª±a tr√™n gi√° tr·ªã hi·ªán t·∫°i c·ªßa c√°c widget
    df_filtered = df_jobs.copy()
    current_filters = st.session_state.filters

    if current_filters.get('location'): # L·ªçc n·∫øu danh s√°ch location c√≥ gi√° tr·ªã
        df_filtered = df_filtered[df_filtered['primary_location'].isin(current_filters['location'])]
    if current_filters.get('category'): # L·ªçc n·∫øu danh s√°ch category c√≥ gi√° tr·ªã
        df_filtered = df_filtered[df_filtered['primary_category'].isin(current_filters['category'])]
    if current_filters.get('experience') and exp_col in df_filtered.columns: # L·ªçc n·∫øu c√≥ kho·∫£ng kinh nghi·ªám
        df_filtered = df_filtered[
            df_filtered[exp_col].between(current_filters['experience'][0], current_filters['experience'][1], inclusive='both')
        ]
    if current_filters.get('salary') and salary_col in df_filtered.columns: # L·ªçc n·∫øu c√≥ kho·∫£ng l∆∞∆°ng
         df_filtered = df_filtered[
             df_filtered[salary_col].between(current_filters['salary'][0], current_filters['salary'][1], inclusive='both')
         ]
    # L∆∞u df ƒë√£ l·ªçc v√†o state ƒë·ªÉ c√°c "trang" d√πng chung
    st.session_state.df_filtered = df_filtered


    # ==============================================================================
    # --- 5. N·ªòI DUNG CH√çNH (Hi·ªÉn th·ªã d·ª±a tr√™n selected_page) ---
    # ==============================================================================

    # >>>>>>>> PH·∫¶N CODE HI·ªÇN TH·ªä C√ÅC TRANG (GI·ªÆ NGUY√äN T·ª™ L·∫¶N TR∆Ø·ªöC) <<<<<<<<
    # (Bao g·ªìm if/elif cho t·ª´ng selected_page v√† code v·∫Ω bi·ªÉu ƒë·ªì t∆∞∆°ng ·ª©ng)
    # M√¨nh s·∫Ω kh√¥ng d√°n l·∫°i to√†n b·ªô ph·∫ßn n√†y ƒë·ªÉ tr√°nh qu√° d√†i, b·∫°n ch·ªâ c·∫ßn ƒë·∫£m b·∫£o
    # ph·∫ßn code t·ª´ section 4 tr·ªü v·ªÅ tr∆∞·ªõc ƒë∆∞·ª£c c·∫≠p nh·∫≠t nh∆∞ tr√™n. Ph·∫ßn section 5
    # s·∫Ω s·ª≠ d·ª•ng st.session_state.df_filtered ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.

    # V√ç D·ª§ C·∫§U TR√öC PH·∫¶N 5:
    # --------------------------------------------------------------------------
    # --- PAGE: TRANG CH·ª¶ & T·ªîNG QUAN ---
    # --------------------------------------------------------------------------
    if selected_page == page_options[0]:
        st.title("üè† Trang Ch·ªß & T·ªïng Quan")
        st.markdown("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi dashboard ph√¢n t√≠ch th·ªã tr∆∞·ªùng tuy·ªÉn d·ª•ng Vi·ªát Nam.")
        if st.session_state.original_filename:
             st.markdown(f"D·ªØ li·ªáu ƒëang ph√¢n t√≠ch t·ª´ file: `{st.session_state.original_filename}`")

        # --- <<< DI CHUY·ªÇN PH·∫¶N KI·ªÇM TRA D·ªÆ LI·ªÜU THI·∫æU L√äN ƒê√ÇY >>> ---
        st.subheader("Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu (T·ªïng th·ªÉ)")
        with st.expander("Xem chi ti·∫øt t·ª∑ l·ªá thi·∫øu c·ªßa c√°c c·ªôt"):
            # Ki·ªÉm tra df_jobs thay v√¨ df_filtered ƒë·ªÉ xem t·ªïng th·ªÉ file g·ªëc
            if 'df_jobs' in st.session_state and st.session_state.df_jobs is not None:
                missing_data = st.session_state.df_jobs.isnull().sum()
                if missing_data.sum() == 0: # N·∫øu kh√¥ng c√≥ c·ªôt n√†o thi·∫øu
                    st.info("Ch√∫c m·ª´ng! D·ªØ li·ªáu g·ªëc kh√¥ng c√≥ gi√° tr·ªã thi·∫øu.")
                else:
                    missing_percent = (missing_data / len(st.session_state.df_jobs)) * 100
                    missing_df = pd.DataFrame({'S·ªë l∆∞·ª£ng thi·∫øu': missing_data, 'T·ª∑ l·ªá thi·∫øu (%)': missing_percent})
                    # Ch·ªâ hi·ªÉn th·ªã c√°c c·ªôt c√≥ d·ªØ li·ªáu thi·∫øu
                    st.dataframe(missing_df[missing_df['S·ªë l∆∞·ª£ng thi·∫øu'] > 0].sort_values('T·ª∑ l·ªá thi·∫øu (%)', ascending=False))
                    st.caption("T·ª∑ l·ªá thi·∫øu cao ·ªü c√°c c·ªôt quan tr·ªçng (l∆∞∆°ng, kinh nghi·ªám, ƒë·ªãa ƒëi·ªÉm, ng√†nh) s·∫Ω ·∫£nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng ph√¢n t√≠ch v√† kh·∫£ nƒÉng hu·∫•n luy·ªán m√¥ h√¨nh AI.")
            else:
                st.info("Ch∆∞a c√≥ d·ªØ li·ªáu g·ªëc ƒë·ªÉ ki·ªÉm tra (Vui l√≤ng t·∫£i file l√™n).")
        st.markdown("---") # Th√™m ƒë∆∞·ªùng k·∫ª ph√¢n c√°ch
        # --- <<< K·∫æT TH√öC PH·∫¶N DI CHUY·ªÇN >>> ---


        # L·∫•y df_filtered t·ª´ state ƒë·ªÉ hi·ªÉn th·ªã ph·∫ßn c√≤n l·∫°i
        df_display = st.session_state.df_filtered

        if df_display is not None and not df_display.empty:
            st.header("üìå T·ªïng Quan (Theo b·ªô l·ªçc)")
            total_jobs_filtered = df_display.shape[0]
            unique_companies_filtered = df_display['company_title'].nunique()
            avg_min_salary_filtered = df_display['min_salary_mil_vnd'].mean()
            avg_min_exp_filtered = df_display['min_experience_years'].mean()

            kpi_cols = st.columns(4)
            kpi_cols[0].metric(label="S·ªë Tin Tuy·ªÉn D·ª•ng", value=f"{total_jobs_filtered:,}")
            kpi_cols[1].metric(label="S·ªë C√¥ng Ty Tuy·ªÉn", value=f"{unique_companies_filtered:,}")
            kpi_cols[2].metric(label="L∆∞∆°ng T·ªëi Thi·ªÉu TB", value=f"{avg_min_salary_filtered:.1f} Tr" if pd.notna(avg_min_salary_filtered) else "N/A")
            kpi_cols[3].metric(label="Kinh Nghi·ªám T·ªëi Thi·ªÉu TB", value=f"{avg_min_exp_filtered:.1f} NƒÉm" if pd.notna(avg_min_exp_filtered) else "N/A")

            st.markdown("---")
            st.subheader("Xem tr∆∞·ªõc d·ªØ li·ªáu (ƒë√£ l·ªçc)")
            st.dataframe(df_display.head(10), use_container_width=True, height=300)

            # N√∫t t·∫£i xu·ªëng
            csv_download = convert_df_to_csv(df_display)
            st.download_button(
               label="üì• T·∫£i xu·ªëng d·ªØ li·ªáu ƒë√£ l·ªçc (CSV)",
               data=csv_download,
               file_name='filtered_job_data.csv',
               mime='text/csv',
               key='download_filtered_home_v2' # ƒê·ªïi key n·∫øu c·∫ßn
            )
        elif uploaded_file is not None: # df_filtered r·ªóng nh∆∞ng ƒë√£ t·∫£i file
             st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc hi·ªán t·∫°i. Vui l√≤ng th·ª≠ ƒëi·ªÅu ch·ªânh b·ªô l·ªçc.")


        # Th√¥ng tin v·ªÅ d·ªØ li·ªáu v√† d·ª± √°n (lu√¥n hi·ªÉn th·ªã)
        st.markdown("---")
        with st.expander("‚ÑπÔ∏è Th√¥ng tin v·ªÅ d·ªØ li·ªáu v√† d·ª± √°n", expanded=False): # Thu g·ªçn m·∫∑c ƒë·ªãnh
            st.markdown(f"""
            * **Ngu·ªìn d·ªØ li·ªáu:** D·ªØ li·ªáu tham kh·∫£o ƒë∆∞·ª£c thu th·∫≠p t·ª´ CareerBuilder.vn (02-03/2023) - File: `{st.session_state.get("original_filename", "N/A")}`.
            * **X·ª≠ l√Ω:** D·ªØ li·ªáu ƒë√£ qua c√°c b∆∞·ªõc l√†m s·∫°ch c∆° b·∫£n (x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, chu·∫©n h√≥a ƒë·ªãnh d·∫°ng...). Xem th√™m ·ªü m·ª•c ki·ªÉm tra d·ªØ li·ªáu thi·∫øu ·ªü tr√™n.
            * **M·ª•c ti√™u ƒë·ªì √°n:** X√¢y d·ª±ng dashboard t∆∞∆°ng t√°c ƒë√°p ·ª©ng y√™u c·∫ßu m√¥n h·ªçc Tr·ª±c quan h√≥a D·ªØ li·ªáu.
                * *Y√™u c·∫ßu ch√≠nh:* D·ªØ li·ªáu VN, ƒë·ªß bi·∫øn/d√≤ng, tr·ª±c quan ph√π h·ª£p & r√µ r√†ng, li√™n k·∫øt, t∆∞∆°ng t√°c, thi·∫øt k·∫ø h·∫•p d·∫´n, ph√¢n t√≠ch s√¢u, t√≠ch h·ª£p AI.
            * **ƒêi·ªÅu h∆∞·ªõng:** S·ª≠ d·ª•ng menu b√™n tr√°i ƒë·ªÉ ch·ªçn ph·∫ßn ph√¢n t√≠ch.
            * **L∆∞u √Ω:** Ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p.
            """)
    # --- END PAGE: TRANG CH·ª¶ & T·ªîNG QUAN ---
    # --------------------------------------------------------------------------

    # ... (C√°c elif cho c√°c trang kh√°c gi·ªØ nguy√™n) ...
    # --------------------------------------------------------------------------
    # --- PAGE: PH√ÇN T√çCH TH·ªä TR∆Ø·ªúNG ---
    # --------------------------------------------------------------------------
    elif selected_page == page_options[1]:
        st.title("üìä Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng Chung")
        df_display = st.session_state.df_filtered # L·∫•y d·ªØ li·ªáu ƒë√£ l·ªçc
        if df_display is None or df_display.empty:
             st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üìà Ph√¢n t√≠ch theo Ng√†nh Ngh·ªÅ")
                tab_cat_count, tab_cat_salary = st.tabs(["S·ªë l∆∞·ª£ng tin", "Ph√¢n b·ªë l∆∞∆°ng"])
                category_counts = df_display['primary_category'].value_counts().reset_index()
                category_counts.columns = ['Ng√†nh ngh·ªÅ', 'S·ªë l∆∞·ª£ng tin']
                with tab_cat_count:
                    st.markdown("##### S·ªë l∆∞·ª£ng tin tuy·ªÉn d·ª•ng theo ng√†nh")
                    top_n_cat = st.slider("Ch·ªçn Top N ng√†nh ngh·ªÅ:", 5, min(30, len(category_counts)), 15, key='slider_cat_count_market')
                    if not category_counts.empty:
                        fig_cat_bar = px.bar(category_counts.head(top_n_cat), x='S·ªë l∆∞·ª£ng tin', y='Ng√†nh ngh·ªÅ', orientation='h', title=f'Top {top_n_cat} Ng√†nh Ngh·ªÅ Nhi·ªÅu Tin Nh·∫•t', text_auto=True, color='S·ªë l∆∞·ª£ng tin', color_continuous_scale=px.colors.sequential.Blues)
                        fig_cat_bar.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(400, top_n_cat*25), showlegend=False, uniformtext_minsize=8, uniformtext_mode='hide')
                        fig_cat_bar.update_traces(textposition='outside')
                        st.plotly_chart(fig_cat_bar, use_container_width=True)
                    else: st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ng√†nh ngh·ªÅ.")
                with tab_cat_salary:
                    st.markdown("##### Ph√¢n b·ªë l∆∞∆°ng t·ªëi thi·ªÉu theo ng√†nh")
                    if 'min_salary_mil_vnd' in df_display.columns and df_display['min_salary_mil_vnd'].notna().any():
                        # L·∫•y danh s√°ch top N t·ª´ slider tr√™n
                        top_categories_list = category_counts.head(top_n_cat)['Ng√†nh ngh·ªÅ'].tolist()
                        df_plot_cat_salary = df_display[df_display['primary_category'].isin(top_categories_list)].dropna(subset=['min_salary_mil_vnd'])
                        if not df_plot_cat_salary.empty:
                            fig_cat_box = px.box(df_plot_cat_salary, x='min_salary_mil_vnd', y='primary_category', title=f'Ph√¢n B·ªë L∆∞∆°ng T·ªëi Thi·ªÉu Top {top_n_cat} Ng√†nh', labels={'min_salary_mil_vnd': 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)', 'primary_category': 'Ng√†nh Ngh·ªÅ'}, points="outliers", color='primary_category', color_discrete_sequence=px.colors.qualitative.Pastel)
                            fig_cat_box.update_layout(yaxis={'categoryorder':'median ascending'}, height=max(400, top_n_cat*30), showlegend=False)
                            st.plotly_chart(fig_cat_box, use_container_width=True)
                            st.caption("Bi·ªÉu ƒë·ªì Boxplot: ƒê∆∞·ªùng gi·ªØa l√† trung v·ªã, h·ªôp l√† kho·∫£ng t·ª© ph√¢n v·ªã (IQR), c√°c ƒëi·ªÉm l√† outliers.")
                        else: st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu l∆∞∆°ng cho ng√†nh ƒë√£ ch·ªçn.")
                    else: st.warning("Thi·∫øu d·ªØ li·ªáu l∆∞∆°ng t·ªëi thi·ªÉu.")

            with col2:
                st.subheader("üìç Ph√¢n t√≠ch theo ƒê·ªãa ƒêi·ªÉm")
                tab_loc_count, tab_loc_salary = st.tabs(["S·ªë l∆∞·ª£ng tin", "Ph√¢n b·ªë l∆∞∆°ng"])
                location_counts = df_display['primary_location'].value_counts().reset_index()
                location_counts.columns = ['ƒê·ªãa ƒëi·ªÉm', 'S·ªë l∆∞·ª£ng tin']
                with tab_loc_count:
                    st.markdown("##### S·ªë l∆∞·ª£ng tin tuy·ªÉn d·ª•ng theo ƒë·ªãa ƒëi·ªÉm")
                    top_n_loc = st.slider("Ch·ªçn Top N ƒë·ªãa ƒëi·ªÉm:", 5, min(30, len(location_counts)), 15, key='slider_loc_count_market')
                    if not location_counts.empty:
                        fig_loc_bar = px.bar(location_counts.head(top_n_loc), x='S·ªë l∆∞·ª£ng tin', y='ƒê·ªãa ƒëi·ªÉm', orientation='h', title=f'Top {top_n_loc} ƒê·ªãa ƒêi·ªÉm Nhi·ªÅu Tin Nh·∫•t', text_auto=True, color='S·ªë l∆∞·ª£ng tin', color_continuous_scale=px.colors.sequential.Greens)
                        fig_loc_bar.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(400, top_n_loc*25), showlegend=False, uniformtext_minsize=8, uniformtext_mode='hide')
                        fig_loc_bar.update_traces(textposition='outside')
                        st.plotly_chart(fig_loc_bar, use_container_width=True)
                    else: st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªãa ƒëi·ªÉm.")
                with tab_loc_salary:
                    st.markdown("##### Ph√¢n b·ªë l∆∞∆°ng t·ªëi thi·ªÉu theo ƒë·ªãa ƒëi·ªÉm")
                    if 'min_salary_mil_vnd' in df_display.columns and df_display['min_salary_mil_vnd'].notna().any():
                        # L·∫•y danh s√°ch top N t·ª´ slider tr√™n
                        top_locations_list = location_counts.head(top_n_loc)['ƒê·ªãa ƒëi·ªÉm'].tolist()
                        df_plot_loc_salary = df_display[df_display['primary_location'].isin(top_locations_list)].dropna(subset=['min_salary_mil_vnd'])
                        if not df_plot_loc_salary.empty:
                            fig_loc_box = px.box(df_plot_loc_salary, x='min_salary_mil_vnd', y='primary_location', title=f'Ph√¢n B·ªë L∆∞∆°ng T·ªëi Thi·ªÉu Top {top_n_loc} ƒê·ªãa ƒêi·ªÉm', labels={'min_salary_mil_vnd': 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)', 'primary_location': 'ƒê·ªãa ƒêi·ªÉm'}, points="outliers", color='primary_location', color_discrete_sequence=px.colors.qualitative.Set2)
                            fig_loc_box.update_layout(yaxis={'categoryorder':'median ascending'}, height=max(400, top_n_loc*30), showlegend=False)
                            st.plotly_chart(fig_loc_box, use_container_width=True)
                            st.caption("Bi·ªÉu ƒë·ªì Boxplot: ƒê∆∞·ªùng gi·ªØa l√† trung v·ªã, h·ªôp l√† kho·∫£ng t·ª© ph√¢n v·ªã (IQR), c√°c ƒëi·ªÉm l√† outliers.")
                        else: st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu l∆∞∆°ng cho ƒë·ªãa ƒëi·ªÉm ƒë√£ ch·ªçn.")
                    else: st.warning("Thi·∫øu d·ªØ li·ªáu l∆∞∆°ng t·ªëi thi·ªÉu.")

            st.markdown("---")
            # --- Stacked Bar Chart Section (ƒë√£ c·∫≠p nh·∫≠t ·ªü l·∫ßn tr∆∞·ªõc) ---
            st.subheader("üìä Ph√¢n B·ªë Ng√†nh Ngh·ªÅ Theo ƒê·ªãa ƒêi·ªÉm (Bi·ªÉu ƒë·ªì c·ªôt ch·ªìng)")
            location_counts_agg = df_display['primary_location'].value_counts() # T√≠nh l·∫°i tr√™n df_display
            category_counts_agg = df_display['primary_category'].value_counts() # T√≠nh l·∫°i tr√™n df_display
            top_n_loc_stack = st.slider("Ch·ªçn Top N ƒë·ªãa ƒëi·ªÉm cho bi·ªÉu ƒë·ªì:", 3, min(20, len(location_counts_agg)), 8, key='slider_loc_stack_v2_market')
            top_n_cat_stack = st.slider("Ch·ªçn Top N ng√†nh ngh·ªÅ ƒë·ªÉ hi·ªÉn th·ªã chi ti·∫øt:", 3, min(20, len(category_counts_agg)), 10, key='slider_cat_stack_v2_market')

            top_loc_list_stack = location_counts_agg.head(top_n_loc_stack).index.tolist()
            top_cat_list_stack = category_counts_agg.head(top_n_cat_stack).index.tolist()

            df_stack_data_loc_filtered = df_display[df_display['primary_location'].isin(top_loc_list_stack)].copy()

            df_stack_data_loc_filtered['category_display'] = df_stack_data_loc_filtered['primary_category'].apply(
                lambda x: x if x in top_cat_list_stack else 'Ng√†nh Kh√°c'
            )
            all_display_categories = top_cat_list_stack + ['Ng√†nh Kh√°c']
            df_stack_data_loc_filtered['category_display'] = pd.Categorical(df_stack_data_loc_filtered['category_display'], categories=all_display_categories, ordered=True)

            location_category_counts_stack = df_stack_data_loc_filtered.groupby(['primary_location', 'category_display'], observed=False).size().reset_index(name='count')

            if not location_category_counts_stack.empty:
                loc_order = location_category_counts_stack.groupby('primary_location')['count'].sum().sort_values(ascending=False).index
                location_category_counts_stack['primary_location'] = pd.Categorical(location_category_counts_stack['primary_location'], categories=loc_order, ordered=True)
                location_category_counts_stack = location_category_counts_stack.sort_values(['primary_location', 'category_display'])

                color_map = {cat: color for cat, color in zip(top_cat_list_stack, px.colors.qualitative.Pastel)}
                color_map['Ng√†nh Kh√°c'] = '#AAAAAA'

                fig_stacked_bar = px.bar(location_category_counts_stack, x='primary_location', y='count', color='category_display', title=f'Ph√¢n B·ªë Top {top_n_cat_stack} Ng√†nh (+ Ng√†nh Kh√°c) t·∫°i Top {top_n_loc_stack} ƒê·ªãa ƒêi·ªÉm', labels={'primary_location': 'ƒê·ªãa ƒêi·ªÉm', 'count': 'S·ªë L∆∞·ª£ng Tin Tuy·ªÉn D·ª•ng', 'category_display': 'Ng√†nh Ngh·ªÅ'}, height=600, color_discrete_map=color_map, custom_data=['category_display'])
                fig_stacked_bar.update_layout(xaxis={'categoryorder':'total descending'}, legend_title_text='Ng√†nh Ngh·ªÅ')
                fig_stacked_bar.update_traces(hovertemplate="<b>ƒê·ªãa ƒëi·ªÉm:</b> %{x}<br><b>Ng√†nh:</b> %{customdata[0]}<br><b>S·ªë l∆∞·ª£ng:</b> %{y}<extra></extra>")
                st.plotly_chart(fig_stacked_bar, use_container_width=True)
                st.caption("M·ªói c·ªôt l√† m·ªôt ƒë·ªãa ƒëi·ªÉm. C√°c m√†u kh√°c nhau th·ªÉ hi·ªán s·ªë l∆∞·ª£ng tin c·ªßa Top N ng√†nh v√† nh√≥m 'Ng√†nh Kh√°c'.")
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu giao nhau gi·ªØa Top N ƒë·ªãa ƒëi·ªÉm v√† Top N ng√†nh ngh·ªÅ ƒë√£ ch·ªçn ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì c·ªôt ch·ªìng.")
            # --- End Stacked Bar Chart ---
    # --- END PAGE: PH√ÇN T√çCH TH·ªä TR∆Ø·ªúNG ---
    # --------------------------------------------------------------------------


    # --------------------------------------------------------------------------
    # --- PAGE: PH√ÇN T√çCH L∆Ø∆†NG & KINH NGHI·ªÜM ---
    # --------------------------------------------------------------------------
    elif selected_page == page_options[2]:
        st.title("üí∞ Ph√¢n T√≠ch L∆∞∆°ng & Kinh Nghi·ªám")
        df_display = st.session_state.df_filtered
        if df_display is None or df_display.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            salary_col = 'min_salary_mil_vnd'
            exp_col = 'min_experience_years'
            if salary_col not in df_display.columns or df_display[salary_col].isnull().all():
                st.error(f"Thi·∫øu d·ªØ li·ªáu c·ªôt l∆∞∆°ng '{salary_col}' ƒë·ªÉ ph√¢n t√≠ch.")
            elif exp_col not in df_display.columns or df_display[exp_col].isnull().all():
                st.error(f"Thi·∫øu d·ªØ li·ªáu c·ªôt kinh nghi·ªám '{exp_col}' ƒë·ªÉ ph√¢n t√≠ch.")
            else:
                st.subheader("Ph√¢n B·ªë M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu")
                fig_hist_min_sal = px.histogram(df_display.dropna(subset=[salary_col]), x=salary_col, nbins=50, title='Ph√¢n B·ªë M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu (Tri·ªáu VND)', labels={salary_col: 'M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu (Tri·ªáu VND)'}, marginal="box")
                fig_hist_min_sal.update_layout(bargap=0.1)
                st.plotly_chart(fig_hist_min_sal, use_container_width=True)

                st.subheader("M·ªëi Quan H·ªá Gi·ªØa L∆∞∆°ng v√† Kinh Nghi·ªám")
                col_scatter, col_box = st.columns(2)
                df_analysis = df_display.dropna(subset=[exp_col, salary_col]).copy()

                with col_scatter:
                    st.markdown("##### Scatter Plot L∆∞∆°ng vs. Kinh Nghi·ªám")
                    if not df_analysis.empty:
                        color_options_scatter = {'primary_category': 'Ng√†nh Ngh·ªÅ', 'primary_location': 'ƒê·ªãa ƒêi·ªÉm', None: 'Kh√¥ng t√¥ m√†u'}
                        selected_color_scatter = st.selectbox("T√¥ m√†u ƒëi·ªÉm theo:", list(color_options_scatter.keys()), format_func=lambda x: color_options_scatter[x], key='scatter_color_exp_salary')
                        fig_scatter = px.scatter(df_analysis, x=exp_col, y=salary_col, title='L∆∞∆°ng T·ªëi Thi·ªÉu theo Kinh Nghi·ªám', labels={exp_col: 'Kinh Nghi·ªám T·ªëi Thi·ªÉu (NƒÉm)', salary_col: 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)'}, color=selected_color_scatter, hover_name='job_title', opacity=0.6, trendline="ols", trendline_scope="overall", trendline_color_override="darkblue", height=500)
                        fig_scatter.update_layout(legend_title_text=color_options_scatter.get(selected_color_scatter, ''))
                        st.plotly_chart(fig_scatter, use_container_width=True)
                        st.caption("M·ªói ƒëi·ªÉm l√† m·ªôt tin tuy·ªÉn d·ª•ng. ƒê∆∞·ªùng m√†u xanh ƒë·∫≠m l√† ƒë∆∞·ªùng xu h∆∞·ªõng t·ªïng th·ªÉ.")
                    else:
                        st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu cho scatter plot.")

                with col_box:
                    st.markdown("##### Box Plot L∆∞∆°ng theo Nh√≥m Kinh Nghi·ªám")
                    if not df_analysis.empty:
                        max_exp_val_box = df_analysis[exp_col].max()
                        if max_exp_val_box <= 5:
                            bins = list(range(-1, int(max_exp_val_box) + 1))
                            labels = [f'{i} nƒÉm' for i in range(int(max_exp_val_box) + 1)]
                        else:
                            bins = [-1, 0, 1, 2, 3, 4, 5, 10, max_exp_val_box]
                            labels = ['0 nƒÉm', '1 nƒÉm', '2 nƒÉm', '3 nƒÉm', '4 nƒÉm', '5 nƒÉm', '6-10 nƒÉm', '10+ nƒÉm']
                            if max_exp_val_box <= 10:
                                bins = bins[:-1]
                                labels = labels[:-1]
                                if max_exp_val_box <= 5:
                                    bins = bins[:-1]
                                    labels = labels[:-1]
                        if len(bins) > 1:
                            try:
                                df_analysis['experience_group'] = pd.cut(df_analysis[exp_col], bins=bins, labels=labels, right=True)
                                df_plot_box = df_analysis.dropna(subset=['experience_group'])
                                if not df_plot_box.empty:
                                    fig_box_exp = px.box(df_plot_box, x='experience_group', y=salary_col, title='Ph√¢n B·ªë L∆∞∆°ng theo Nh√≥m Kinh Nghi·ªám', labels={'experience_group': 'Nh√≥m Kinh Nghi·ªám', salary_col: 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)'}, points="outliers", color='experience_group', color_discrete_sequence=px.colors.qualitative.Bold, height=500)
                                    fig_box_exp.update_layout(showlegend=False)
                                    st.plotly_chart(fig_box_exp, use_container_width=True)
                                else:
                                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi ph√¢n nh√≥m kinh nghi·ªám.")
                            except Exception as e:
                                st.warning(f"L·ªói khi ph√¢n nh√≥m kinh nghi·ªám: {e}. Hi·ªÉn th·ªã theo t·ª´ng nƒÉm (<=10):")
                                df_plot_box_fb = df_analysis[df_analysis[exp_col] <= 10]
                                if not df_plot_box_fb.empty:
                                    fig_box_exp_fb = px.box(df_plot_box_fb, x=exp_col, y=salary_col, title='Ph√¢n B·ªë L∆∞∆°ng theo Kinh Nghi·ªám (T·ª´ng nƒÉm <= 10)', labels={exp_col: 'Kinh Nghi·ªám (NƒÉm)', salary_col: 'L∆∞∆°ng T·ªëi Thi·ªÉu (Tr VND)'}, points="outliers")
                                    fig_box_exp_fb.update_xaxes(type='category')
                                    st.plotly_chart(fig_box_exp_fb, use_container_width=True)
                                else:
                                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu kinh nghi·ªám <= 10 nƒÉm.")
                        else:
                            st.info("Kh√¥ng ƒë·ªß kho·∫£ng kinh nghi·ªám ƒë·ªÉ ph√¢n nh√≥m.")
                    else:
                        st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu cho box plot l∆∞∆°ng theo kinh nghi·ªám.")

                # --- Bi·ªÉu ƒê·ªì Xu H∆∞·ªõng (ƒê√£ th√™m v√†o ƒë√¢y) ---
                st.subheader("Xu H∆∞·ªõng L∆∞∆°ng Theo Kinh Nghi·ªám")
                st.markdown('<div class="section-title">Bi·ªÉu ƒê·ªì Xu H∆∞·ªõng</div>', unsafe_allow_html=True)
                grouped = df_display.groupby("min_experience_years")[["min_salary_mil_vnd", "max_salary_mil_vnd"]].mean().reset_index()
                if grouped.empty:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì xu h∆∞·ªõng.")
                else:
                    fig, ax = plt.subplots(figsize=(12, 7))
                    sns.lineplot(x="min_experience_years", y="min_salary_mil_vnd", data=grouped, label="M·ª©c L∆∞∆°ng T·ªëi Thi·ªÉu", ax=ax, color=PALETTE[0])
                    sns.lineplot(x="min_experience_years", y="max_salary_mil_vnd", data=grouped, label="M·ª©c L∆∞∆°ng T·ªëi ƒêa", ax=ax, color=PALETTE[1])
                    ax.set_title("M·ª©c L∆∞∆°ng Theo Kinh Nghi·ªám (Bi·ªÉu ƒê·ªì ƒê∆∞·ªùng)", fontsize=14, pad=15)
                    ax.set_xlabel("S·ªë NƒÉm Kinh Nghi·ªám T·ªëi Thi·ªÉu", fontsize=12)
                    ax.set_ylabel("M·ª©c L∆∞∆°ng (Tri·ªáu VND)", fontsize=12)
                    ax.legend(title="Lo·∫°i L∆∞∆°ng")
                    plt.grid(True, linestyle='--', alpha=0.7)
                    plt.tight_layout()
                    st.pyplot(fig)
                    pdf_buffer = save_fig_to_pdf(fig)
                    st.download_button(
                        label="üì• L∆∞u Bi·ªÉu ƒê·ªì D∆∞·ªõi D·∫°ng PDF",
                        data=pdf_buffer,
                        file_name="LineChart_MucLuong_KinhNghiem.pdf",
                        mime="application/pdf"
                    )

                st.markdown("---")
                st.subheader("üìù Nh·∫≠n X√©t")
                st.markdown("""
                * **Ph√¢n b·ªë l∆∞∆°ng:** Bi·ªÉu ƒë·ªì histogram th∆∞·ªùng cho th·∫•y l∆∞∆°ng t·∫≠p trung ·ªü m·ª©c th·∫•p ƒë·∫øn trung b√¨nh v√† c√≥ m·ªôt s·ªë gi√° tr·ªã r·∫•t cao (l·ªách ph·∫£i).
                * **L∆∞∆°ng & Kinh nghi·ªám:** C√≥ xu h∆∞·ªõng l∆∞∆°ng tƒÉng theo kinh nghi·ªám, nh∆∞ng m·ª©c ƒë·ªô tƒÉng v√† s·ª± bi·∫øn ƒë·ªông kh√°c nhau t√πy ng√†nh ngh·ªÅ v√† ƒë·ªãa ƒëi·ªÉm.
                * **Xu h∆∞·ªõng l∆∞∆°ng:** Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho th·∫•y m·ª©c l∆∞∆°ng trung b√¨nh (t·ªëi thi·ªÉu v√† t·ªëi ƒëa) c√≥ xu h∆∞·ªõng tƒÉng theo s·ªë nƒÉm kinh nghi·ªám, v·ªõi m·ª©c l∆∞∆°ng t·ªëi ƒëa th∆∞·ªùng cao h∆°n ƒë√°ng k·ªÉ ·ªü c√°c m·ª©c kinh nghi·ªám cao.
                """)
    # --- END PAGE: PH√ÇN T√çCH L∆Ø∆†NG & KINH NGHI·ªÜM ---
    # --------------------------------------------------------------------------


    # --------------------------------------------------------------------------
    # --- PAGE: PH√ÇN T√çCH K·ª∏ NƒÇNG ---
    # --------------------------------------------------------------------------
    elif selected_page == page_options[3]:
        st.title("üõ†Ô∏è Ph√¢n T√≠ch K·ªπ NƒÉng Y√™u C·∫ßu")
        df_display = st.session_state.df_filtered # L·∫•y d·ªØ li·ªáu ƒë√£ l·ªçc
        if df_display is None or df_display.empty:
             st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            req_col = 'job_requirements'
            if req_col not in df_display.columns or df_display[req_col].isnull().all():
                st.error(f"Thi·∫øu d·ªØ li·ªáu c·ªôt '{req_col}' ƒë·ªÉ ph√¢n t√≠ch k·ªπ nƒÉng.")
            else:
                st.subheader("K·ªπ NƒÉng Ph·ªï Bi·∫øn Nh·∫•t")
                num_display_skills = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng k·ªπ nƒÉng h√†ng ƒë·∫ßu:", 10, 50, 20, key='slider_skills_page')
                requirements_text = df_display[req_col]

                if not requirements_text.empty:
                    with st.spinner("ƒêang tr√≠ch xu·∫•t v√† ph√¢n t√≠ch k·ªπ nƒÉng..."):
                        skills_df, full_text_req = extract_skills_from_requirements(requirements_text, num_display_skills)

                    if not skills_df.empty:
                        col_bar, col_cloud = st.columns([0.6, 0.4])
                        with col_bar:
                            st.markdown(f"##### Top {num_display_skills} K·ªπ NƒÉng Ph·ªï Bi·∫øn")
                            fig_skills = px.bar(skills_df, x='S·ªë l·∫ßn xu·∫•t hi·ªán', y='K·ªπ nƒÉng', orientation='h', title=f'Top {num_display_skills} K·ªπ NƒÉng Ph·ªï Bi·∫øn', text='S·ªë l·∫ßn xu·∫•t hi·ªán', color='S·ªë l·∫ßn xu·∫•t hi·ªán', color_continuous_scale=px.colors.sequential.Viridis)
                            fig_skills.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(400, num_display_skills*20), showlegend=False, uniformtext_minsize=8, uniformtext_mode='hide')
                            fig_skills.update_traces(textposition='outside')
                            st.plotly_chart(fig_skills, use_container_width=True)
                        with col_cloud:
                            st.markdown("##### Word Cloud K·ªπ NƒÉng")
                            try:
                                skill_frequencies = {skill: count for skill, count in skills_df.values}
                                if skill_frequencies:
                                    wordcloud = WordCloud(width=800, height=600, background_color='white', max_words=100, colormap='viridis', collocations=False, contour_width=1, contour_color='steelblue').generate_from_frequencies(skill_frequencies)
                                    fig_cloud, ax = plt.subplots(figsize=(10, 7))
                                    ax.imshow(wordcloud, interpolation='bilinear')
                                    ax.axis('off')
                                    st.pyplot(fig_cloud)
                                    st.caption("K√≠ch th∆∞·ªõc ch·ªØ th·ªÉ hi·ªán t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa k·ªπ nƒÉng.")
                                else: st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu t·∫°o Word Cloud.")
                            except ImportError:
                                st.warning("Vui l√≤ng c√†i ƒë·∫∑t th∆∞ vi·ªán `wordcloud` v√† `matplotlib` ƒë·ªÉ xem Word Cloud.")
                            except Exception as e: st.warning(f"L·ªói t·∫°o Word Cloud: {e}")
                    else:
                        st.info("Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng n√†o (theo danh s√°ch keywords) trong d·ªØ li·ªáu ƒë√£ l·ªçc.")
                else:
                    st.info("Kh√¥ng c√≥ y√™u c·∫ßu c√¥ng vi·ªác n√†o trong d·ªØ li·ªáu ƒë√£ l·ªçc.")

                st.markdown("---")
                st.subheader("üìù Nh·∫≠n X√©t")
                st.markdown("""
                * Bi·ªÉu ƒë·ªì c·ªôt v√† Word Cloud gi√∫p x√°c ƒë·ªãnh c√°c k·ªπ nƒÉng ƒë∆∞·ª£c y√™u c·∫ßu nhi·ªÅu nh·∫•t.
                * **Quan tr·ªçng:** K·∫øt qu·∫£ ph·ª• thu·ªôc l·ªõn v√†o danh s√°ch `skills_keywords` trong code. C·∫ßn r√† so√°t v√† b·ªï sung c√°c k·ªπ nƒÉng li√™n quan! Ph∆∞∆°ng ph√°p ƒë·∫øm t·ª´ kh√≥a c√≤n h·∫°n ch·∫ø.
                """)
    # --- END PAGE: PH√ÇN T√çCH K·ª∏ NƒÇNG ---
    # --------------------------------------------------------------------------


    # --------------------------------------------------------------------------
    # --- PAGE: D·ª∞ ƒêO√ÅN L∆Ø∆†NG (AI) ---
    # --------------------------------------------------------------------------
    elif selected_page == page_options[4]:
        st.title("ü§ñ D·ª± ƒêo√°n L∆∞∆°ng T·ªëi Thi·ªÉu (AI)")
        st.markdown("S·ª≠ d·ª•ng m√¥ h√¨nh Machine Learning (Random Forest) ƒë·ªÉ d·ª± ƒëo√°n m·ª©c l∆∞∆°ng t·ªëi thi·ªÉu d·ª±a tr√™n kinh nghi·ªám, ng√†nh ngh·ªÅ v√† ƒë·ªãa ƒëi·ªÉm.")

        df_display = st.session_state.df_filtered # L·∫•y d·ªØ li·ªáu ƒë√£ l·ªçc

        model_features = ['min_experience_years', 'primary_category', 'primary_location']
        target = 'min_salary_mil_vnd'
        required_model_cols = model_features + [target]
        min_records_threshold = 50 # Ng∆∞·ª°ng t·ªëi thi·ªÉu

        if df_display is None or df_display.empty:
             st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
        else:
            missing_model_cols = [col for col in required_model_cols if col not in df_display.columns]
            if missing_model_cols:
                 st.error(f"Thi·∫øu c√°c c·ªôt c·∫ßn thi·∫øt cho m√¥ h√¨nh AI: {', '.join(missing_model_cols)}")
            else:
                # L·∫•y d·ªØ li·ªáu s·∫°ch cho m√¥ h√¨nh T·ª™ df_display
                df_model_data = df_display[required_model_cols].copy().dropna()
                num_valid_records = df_model_data.shape[0]

                st.info(f"S·ªë l∆∞·ª£ng b·∫£n ghi h·ª£p l·ªá (ƒë·ªß d·ªØ li·ªáu cho c√°c c·ªôt: {', '.join(required_model_cols)}) sau khi l·ªçc: **{num_valid_records}**")

                if num_valid_records < min_records_threshold:
                    st.error(f"S·ªë l∆∞·ª£ng b·∫£n ghi h·ª£p l·ªá ({num_valid_records}) th·∫•p h∆°n ng∆∞·ª°ng t·ªëi thi·ªÉu ({min_records_threshold}). Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh ƒë√°ng tin c·∫≠y.")
                    st.markdown("**G·ª£i √Ω:** Th·ª≠ n·ªõi l·ªèng c√°c b·ªô l·ªçc d·ªØ li·ªáu ·ªü sidebar.")
                    st.session_state.model_results = None # Reset tr·∫°ng th√°i m√¥ h√¨nh
                    st.session_state.model_metrics = {}
                    st.session_state.model_pipeline = None
                else:
                    # --- Hu·∫•n luy·ªán ho·∫∑c t·∫£i l·∫°i m√¥ h√¨nh ---
                    col_train_btn, col_model_status = st.columns([0.3, 0.7])
                    with col_train_btn:
                         if st.button("üîÑ Hu·∫•n luy·ªán/C·∫≠p nh·∫≠t m√¥ h√¨nh"):
                             st.session_state.model_results = None
                             st.session_state.model_metrics = {}
                             st.session_state.model_pipeline = None
                             st.info("ƒê√£ x√≥a m√¥ h√¨nh c≈©. ƒêang chu·∫©n b·ªã hu·∫•n luy·ªán l·∫°i...") # Th√™m th√¥ng b√°o

                    if st.session_state.model_pipeline is None:
                         with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi {num_valid_records} b·∫£n ghi..."):
                            # Ch·ªâ truy·ªÅn df_model_data (ƒë√£ dropna) v√†o h√†m hu·∫•n luy·ªán
                            results_df, rmse, mae, r2, oob = train_salary_model(df_model_data)
                            if results_df is not None:
                                st.session_state.model_results = results_df
                                st.session_state.model_metrics = {'RMSE': rmse, 'MAE': mae, 'R2 Score': r2, 'OOB Score': oob}
                                st.success(f"Hu·∫•n luy·ªán m√¥ h√¨nh th√†nh c√¥ng tr√™n {num_valid_records} b·∫£n ghi!")
                            else:
                                st.session_state.model_pipeline = None # ƒê·∫£m b·∫£o state l√† None n·∫øu l·ªói
                                # Th√¥ng b√°o l·ªói ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã trong h√†m train_salary_model
                    else:
                         with col_model_status:
                             # Hi·ªÉn th·ªã th√¥ng tin model ƒë√£ train
                             if st.session_state.model_metrics:
                                  metrics = st.session_state.model_metrics
                                  st.success(f"‚úîÔ∏è M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (R2: {metrics.get('R2 Score', 0):.3f}). Nh·∫•n n√∫t b√™n c·∫°nh ƒë·ªÉ c·∫≠p nh·∫≠t.")
                             else:
                                 st.success("‚úîÔ∏è M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán.")


                    # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√°nh gi√° v√† giao di·ªán d·ª± ƒëo√°n ---
                    if st.session_state.model_pipeline is not None and st.session_state.model_results is not None:
                        st.subheader("ƒê√°nh Gi√° M√¥ H√¨nh")
                        metrics = st.session_state.model_metrics
                        oob_score_val = metrics.get('OOB Score')
                        oob_text = f"(OOB: {oob_score_val:.3f})" if oob_score_val else ""

                        m_col1, m_col2, m_col3 = st.columns(3)
                        m_col1.metric("RMSE (L·ªói TB)", f"{metrics.get('RMSE', 0):.2f} Tr")
                        m_col2.metric("MAE (L·ªói Tuy·ªát ƒë·ªëi TB)", f"{metrics.get('MAE', 0):.2f} Tr")
                        m_col3.metric(f"R2 Score {oob_text}", f"{metrics.get('R2 Score', 0):.3f}")
                        st.caption(f"ƒê√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra (20% c·ªßa {num_valid_records}). OOB Score l√† ƒë·ªô ch√≠nh x√°c ∆∞·ªõc t√≠nh tr√™n d·ªØ li·ªáu ch∆∞a th·∫•y khi hu·∫•n luy·ªán RF.")

                        results_df = st.session_state.model_results
                        fig_pred = px.scatter(results_df, x='Th·ª±c t·∫ø', y='D·ª± ƒëo√°n', title='K·∫øt Qu·∫£ D·ª± ƒêo√°n vs. Th·ª±c T·∫ø', labels={'Th·ª±c t·∫ø': 'L∆∞∆°ng Th·ª±c T·∫ø (Tr VND)', 'D·ª± ƒëo√°n': 'L∆∞∆°ng D·ª± ƒêo√°n (Tr VND)'}, opacity=0.7, height=500)
                        min_val = min(results_df['Th·ª±c t·∫ø'].min(), results_df['D·ª± ƒëo√°n'].min()) * 0.95 # Add padding
                        max_val = max(results_df['Th·ª±c t·∫ø'].max(), results_df['D·ª± ƒëo√°n'].max()) * 1.05 # Add padding
                        fig_pred.add_shape(type="line", x0=min_val, y0=min_val, x1=max_val, y1=max_val, line=dict(color="red", width=2, dash="dash"), name="L√Ω t∆∞·ªüng")
                        fig_pred.update_xaxes(range=[min_val, max_val])
                        fig_pred.update_yaxes(range=[min_val, max_val])
                        st.plotly_chart(fig_pred, use_container_width=True)

                        st.subheader("Th·ª≠ D·ª± ƒêo√°n L∆∞∆°ng")
                        # L·∫•y danh s√°ch t·ª´ df_jobs g·ªëc ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ ƒë·ªß l·ª±a ch·ªçn
                        all_categories_model = sorted(st.session_state.df_jobs['primary_category'].astype(str).unique())
                        all_locations_model = sorted(st.session_state.df_jobs['primary_location'].astype(str).unique())
                        with st.form("prediction_form"):
                              pred_exp = st.number_input("S·ªë nƒÉm kinh nghi·ªám:", min_value=0.0, max_value=50.0, value=2.0, step=0.5)
                              # S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh t·ª´ b·ªô l·ªçc ch√≠nh n·∫øu c√≥ th·ªÉ
                              default_cat_index = all_categories_model.index(st.session_state.filters['category'][0]) if st.session_state.filters.get('category') and st.session_state.filters['category'][0] in all_categories_model else 0
                              default_loc_index = all_locations_model.index(st.session_state.filters['location'][0]) if st.session_state.filters.get('location') and st.session_state.filters['location'][0] in all_locations_model else 0

                              pred_cat = st.selectbox("Ng√†nh ngh·ªÅ:", options=all_categories_model, index=default_cat_index)
                              pred_loc = st.selectbox("ƒê·ªãa ƒëi·ªÉm:", options=all_locations_model, index=default_loc_index)
                              submitted = st.form_submit_button("D·ª± ƒëo√°n m·ª©c l∆∞∆°ng t·ªëi thi·ªÉu")
                              if submitted:
                                  input_data = pd.DataFrame({'min_experience_years': [pred_exp],'primary_category': [pred_cat],'primary_location': [pred_loc]})
                                  try:
                                      prediction = st.session_state.model_pipeline.predict(input_data)
                                      st.success(f"M·ª©c l∆∞∆°ng t·ªëi thi·ªÉu d·ª± ƒëo√°n: **{prediction[0]:.1f} Tri·ªáu VND**")
                                  except Exception as e: st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")

                        st.markdown("---")
                        st.subheader("üìù Nh·∫≠n X√©t")
                        st.markdown(f"""
                        * **M√¥ h√¨nh:** Random Forest d·ª± ƒëo√°n l∆∞∆°ng d·ª±a tr√™n kinh nghi·ªám, ng√†nh ngh·ªÅ, ƒë·ªãa ƒëi·ªÉm.
                        * **ƒê√°nh gi√°:** C√°c ch·ªâ s·ªë RMSE ({metrics.get('RMSE', 0):.2f} Tr), MAE ({metrics.get('MAE', 0):.2f} Tr), v√† R2 Score ({metrics.get('R2 Score', 0):.3f}) cho th·∫•y m·ª©c ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm tra. OOB score ({oob_score_val:.3f} n·∫øu c√≥) l√† m·ªôt ∆∞·ªõc t√≠nh kh√°c v·ªÅ hi·ªáu su·∫•t.
                        * **H·∫°n ch·∫ø:** K·∫øt qu·∫£ ch·ªâ mang t√≠nh tham kh·∫£o, ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu, b·ªô l·ªçc hi·ªán t·∫°i v√† s·ª± ƒë∆°n gi·∫£n c·ªßa m√¥ h√¨nh (ch·ªâ d√πng 3 y·∫øu t·ªë).
                        """)
                    elif st.session_state.model_pipeline is None and num_valid_records >= min_records_threshold:
                         st.info("Nh·∫•n n√∫t 'Hu·∫•n luy·ªán/C·∫≠p nh·∫≠t m√¥ h√¨nh' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
                         
    elif selected_page == page_options[5]:
        st.header("üìà Th·ªëng K√™ M√¥ T·∫£")
        df = st.session_state.df_filtered
        if df is None or df.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë·ªÉ hi·ªÉn th·ªã ph√¢n t√≠ch n√†y.")
        else:
            st.markdown("""
                <style>
                .section-title {
                    font-size: 24px;
                    font-weight: 500;
                    margin-bottom: 15px;
                    color: #333333;
                }
                .chart-title {
                    font-size: 18px;
                    font-weight: bold;
                    color: #FF851B;
                    margin-bottom: 10px;
                }
                .debug-expander {
                    background-color: #f9f9f9;
                    padding: 10px;
                    border-radius: 5px;
                }
                </style>
            """, unsafe_allow_html=True)
            tab1, tab2, tab3 = st.tabs(["üìä Th√¥ng Tin D·ªØ Li·ªáu", "üìà Ph√¢n Ph·ªëi Bi·∫øn S·ªë", "üìâ Ph√¢n Ph·ªëi Bi·∫øn Ph√¢n Lo·∫°i"])
            with tab1:
                st.markdown('<div class="section-title">Th√¥ng Tin D·ªØ Li·ªáu</div>', unsafe_allow_html=True)
                st.dataframe(df.describe(include='all').style.set_properties(**{
                    'background-color': '#ffffff',
                    'border': '1px solid #e0e0e0',
                    'padding': '5px',
                    'text-align': 'left'
                }), height=300)
            with tab2:
                st.markdown('<div class="section-title">Ph√¢n Ph·ªëi Bi·∫øn S·ªë</div>', unsafe_allow_html=True)
                numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
                num_select = st.selectbox("Ch·ªçn m·ªôt bi·∫øn s·ªë ƒë·ªÉ xem ph√¢n ph·ªëi:", numeric_cols)
                if num_select:
                    chart_type = st.radio("Ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì:", ["Histogram (v·ªõi KDE)", "Boxplot", "KDE Plot"])
                    st.markdown('<div class="chart-title">Bi·ªÉu ƒê·ªì Ph√¢n Ph·ªëi</div>', unsafe_allow_html=True)
                    fig, ax = plt.subplots(figsize=(14, 7))
                    if chart_type == "Histogram (v·ªõi KDE)":
                        sns.histplot(df[num_select].dropna(), kde=True, color=PALETTE[0], ax=ax)
                        ax.set_title(f"Ph√¢n b·ªë c·ªßa {num_select} (Histogram v·ªõi KDE)", fontsize=14, pad=15)
                    elif chart_type == "Boxplot":
                        sns.boxplot(y=df[num_select].dropna(), color=PALETTE[1], ax=ax)
                        ax.set_title(f"Ph√¢n b·ªë c·ªßa {num_select} (Boxplot)", fontsize=14, pad=15)
                    elif chart_type == "KDE Plot":
                        sns.kdeplot(df[num_select].dropna(), color=PALETTE[2], fill=True, ax=ax)
                        ax.set_title(f"Ph√¢n b·ªë c·ªßa {num_select} (KDE Plot)", fontsize=14, pad=15)
                    ax.set_xlabel(num_select, fontsize=12)
                    ax.set_ylabel('S·ªë l∆∞·ª£ng' if chart_type != "Boxplot" else '', fontsize=12)
                    plt.tight_layout()
                    st.pyplot(fig)
                    pdf_buffer = save_fig_to_pdf(fig)
                    st.download_button(
                        label="üì• L∆∞u Bi·ªÉu ƒê·ªì D∆∞·ªõi D·∫°ng PDF",
                        data=pdf_buffer,
                        file_name=f"PhanBo_{num_select}_{chart_type}.pdf",
                        mime="application/pdf"
                    )
            with tab3:
                st.markdown('<div class="section-title">Ph√¢n Ph·ªëi Bi·∫øn Ph√¢n Lo·∫°i</div>', unsafe_allow_html=True)
                st.markdown('<div class="filter-box">', unsafe_allow_html=True)
                unique_locations = df['primary_location'].dropna().unique().tolist()
                selected_locations = st.multiselect(
                    "üìç L·ªçc theo ƒë·ªãa ƒëi·ªÉm:",
                    options=unique_locations,
                    default=unique_locations,
                    key="filter_locations_categorical"
                )
                st.markdown('</div>', unsafe_allow_html=True)
                filtered_df = df.copy()
                if selected_locations:
                    filtered_df = filtered_df[filtered_df['primary_location'].isin(selected_locations)]
                if filtered_df.empty:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l·ªçc. Vui l√≤ng ch·ªçn l·∫°i ƒë·ªãa ƒëi·ªÉm.")
                else:
                    cat_cols = ['order', 'position', 'primary_category']
                    cat_select = st.selectbox("Ch·ªçn m·ªôt bi·∫øn ph√¢n lo·∫°i ƒë·ªÉ xem ph√¢n ph·ªëi:", cat_cols)
                    if cat_select:
                        grouped = filtered_df.groupby('primary_location')[cat_select].value_counts().unstack(fill_value=0)
                        grouped = grouped.reindex(selected_locations)
                        grouped = grouped.sort_index(ascending=False)
                        fig, ax = plt.subplots(figsize=(20, 16))
                        grouped.plot(kind='bar', stacked=True, ax=ax, colormap='tab20')
                        ax.set_title(f"Ph√¢n Ph·ªëi '{cat_select}' Theo ƒê·ªãa ƒêi·ªÉm ƒê√£ Ch·ªçn", fontsize=16, pad=10)
                        ax.set_xlabel("ƒê·ªãa ƒëi·ªÉm", fontsize=14)
                        ax.set_ylabel("S·ªë l∆∞·ª£ng", fontsize=14)
                        plt.xticks(rotation=90, ha='right')
                        plt.tight_layout()
                        st.pyplot(fig)
                        pdf_buffer = save_fig_to_pdf(fig)
                        st.download_button(
                            label="üì• L∆∞u Bi·ªÉu ƒê·ªì D∆∞·ªõi D·∫°ng PDF",
                            data=pdf_buffer,
                            file_name=f"PhanBo_{cat_select}_TheoDiaDiem.pdf",
                            mime="application/pdf"
                        )

    # --- END PAGE: D·ª∞ ƒêO√ÅN L∆Ø∆†NG (AI) ---
    # --------------------------------------------------------------------------

# --- Th√¥ng b√°o n·∫øu ch∆∞a t·∫£i file ---
elif uploaded_file is None:
     st.info("üí° Vui l√≤ng t·∫£i l√™n t·ªáp CSV qua thanh b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
     # st.image("link_anh_chao_mung.jpg")


# --- Footer (Lu√¥n hi·ªÉn th·ªã) ---
st.sidebar.markdown("---")
st.sidebar.markdown(f"¬© {pd.Timestamp.now().year} - [Nh√≥m 3]") # NƒÉm t·ª± ƒë·ªông
st.sidebar.info("Dashboard ƒë∆∞·ª£c t·∫°o b·∫±ng Streamlit.")